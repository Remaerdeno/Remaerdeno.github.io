<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://www.reamder.com">
  <title>梦想家的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="梦想家的博客">
<meta property="og:url" content="http://www.reamder.com/page/4/index.html">
<meta property="og:site_name" content="梦想家的博客">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="梦想家的博客">
  
    <link rel="alternative" href="/atom.xml" title="梦想家的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/assets/blogImg/timg.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Remaerd</a></h1>
		</hgroup>
		
		<p class="header-subtitle">以梦为马 不负韶华</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories/机器学习">机器学习</a></li>
	        
				<li><a href="/categories/深度学习">深度学习</a></li>
	        
				<li><a href="/categories/数学之美">数学之美</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Remaerdeno" title="github"><i class="icon-github"></i></a>
		        
					<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/Remaerdeno" title="zhihu"><i class="icon-zhihu"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:Remaerdeno@Gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/blogImg/timg.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Remaerd</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>以梦为马 不负韶华<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Remaerdeno" title="github"><i class="icon-github"></i></a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/Remaerdeno" title="zhihu"><i class="icon-zhihu"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:Remaerdeno@Gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 25%"><a href="/">主页</a></li>
		        
					<li style="width: 25%"><a href="/categories/机器学习">机器学习</a></li>
		        
					<li style="width: 25%"><a href="/categories/深度学习">深度学习</a></li>
		        
					<li style="width: 25%"><a href="/categories/数学之美">数学之美</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-改善深层神经网络2" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/改善深层神经网络2/">优化算法</a>
    </h1>
  

        
        <a href="/2018/02/05/改善深层神经网络2/" class="archive-article-date">
  	<time datetime="2018-02-05T08:36:15.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Mini-batch-梯度下降法"><a href="#1-Mini-batch-梯度下降法" class="headerlink" title="1. Mini-batch 梯度下降法"></a><strong>1. Mini-batch 梯度下降法</strong></h2><p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。</p>
<p>但是如果每次处理训练数据的一部分，即用其子集进行梯度下降，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为Mini-batch。</p>
<p><strong>算法核心</strong></p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-a871740e81fd724832bac62243dee01e_hd.jpg" alt="img"></p>
<p>对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。</p>
<p><strong>不同size大小的比较</strong></p>
<p>普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-d7374a43267473cd13bfec8764a32471_hd.jpg" alt="img"></p>
<ul>
<li>batch梯度下降：</li>
</ul>
<ol>
<li>对所有m个训练样本执行一次梯度下降，每一次迭代时间较长；</li>
<li>Cost function 总是向减小的方向下降。</li>
</ol>
<ul>
<li>随机梯度下降：</li>
</ul>
<ol>
<li>对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；</li>
<li>Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。</li>
</ol>
<ul>
<li>Mini-batch梯度下降：</li>
</ul>
<ol>
<li>选择一个 <img src="https://www.zhihu.com/equation?tex=1%3Csize%3Cm" alt="1&lt;size&lt;m"> 的合适的size进行Mini-batch梯度下降，可以实现快速学习，也应用了向量化带来的好处；</li>
<li>Cost function的下降处于前两者之间。</li>
</ol>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-2cdd92c6706eaf29b80694c1213804bc_hd.jpg" alt="img"></p>
<p><strong>Mini-batch 大小的选择</strong></p>
<ul>
<li>如果训练样本的大小比较小时，如 <img src="https://www.zhihu.com/equation?tex=m%5Cleqslant+2000" alt="m\leqslant 2000"> 时 —— 选择batch梯度下降法；</li>
<li>如果训练样本的大小比较大时，典型的大小为： <img src="https://www.zhihu.com/equation?tex=2%5E%7B6%7D%E3%80%812%5E%7B7%7D%E3%80%81%5Ccdots%E3%80%812%5E%7B10%7D" alt="2^{6}、2^{7}、\cdots、2^{10}"> ；</li>
<li>Mini-batch的大小要符合CPU/GPU内存。</li>
</ul>
<h2 id="2-指数加权平均"><a href="#2-指数加权平均" class="headerlink" title="2. 指数加权平均"></a><strong>2. 指数加权平均</strong></h2><p>指数加权平均的关键函数：</p>
<p><img src="https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cbeta+v_%7Bt-1%7D%2B%281-%5Cbeta%29%5Ctheta_%7Bt%7D" alt="v_{t} = \beta v_{t-1}+(1-\beta)\theta_{t}"></p>
<p>下图是一个关于天数和温度的散点图：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-2969f0fa8cfb79021856d26e2c269306_hd.jpg" alt="img"></p>
<ul>
<li>当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta+%3D0.9" alt="\beta =0.9"> 时，指数加权平均最后的结果如图中红色线所示；</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta+%3D0.98" alt="\beta =0.98"> 时，指数加权平均最后的结果如图中绿色线所示；</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta+%3D0.5" alt="\beta =0.5"> 时，指数加权平均最后的结果如下图中黄色线所示；</li>
</ul>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-44d786b0b58dba00c780e398259a58a7_hd.jpg" alt="img"></p>
<p><strong>理解指数加权平均</strong></p>
<p>例子，当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta+%3D0.9" alt="\beta =0.9"> 时：</p>
<p><img src="https://www.zhihu.com/equation?tex=v_%7B100%7D+%3D+0.9v_%7B99%7D%2B0.1%5Ctheta_%7B100%7D%5C%5Cv_%7B99%7D+%3D+0.9v_%7B98%7D%2B0.1%5Ctheta_%7B99%7D%5C%5Cv_%7B98%7D+%3D+0.9v_%7B97%7D%2B0.1%5Ctheta_%7B98%7D%5C%5C+%5Cldots" alt="v_{100} = 0.9v_{99}+0.1\theta_{100}\\v_{99} = 0.9v_{98}+0.1\theta_{99}\\v_{98} = 0.9v_{97}+0.1\theta_{98}\\ \ldots"></p>
<p>展开，有：</p>
<p><img src="https://www.zhihu.com/equation?tex=v_%7B100%7D%3D0.1%5Ctheta_%7B100%7D%2B0.9%280.1%5Ctheta_%7B99%7D%2B0.9%280.1%5Ctheta_%7B98%7D%2B0.9v_%7B97%7D%29%29%5C%5C%3D0.1%5Ctheta_%7B100%7D%2B0.1%5Ctimes0.9%5Ctheta_%7B99%7D%2B0.1%5Ctimes%280.9%29%5E%7B2%7D%5Ctheta_%7B98%7D%2B0.1%5Ctimes%280.9%29%5E%7B3%7D%5Ctheta_%7B97%7D%2B%5Ccdots" alt="v_{100}=0.1\theta_{100}+0.9(0.1\theta_{99}+0.9(0.1\theta_{98}+0.9v_{97}))\\=0.1\theta_{100}+0.1\times0.9\theta_{99}+0.1\times(0.9)^{2}\theta_{98}+0.1\times(0.9)^{3}\theta_{97}+\cdots"></p>
<p>上式中所有 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta"> 前面的系数相加起来为1或者接近于1，称之为偏差修正。</p>
<p>总体来说存在， <img src="https://www.zhihu.com/equation?tex=%281-%5Cvarepsilon%29%5E%7B1%2F%5Cvarepsilon%7D%3D%5Cdfrac%7B1%7D%7Be%7D" alt="(1-\varepsilon)^{1/\varepsilon}=\dfrac{1}{e}"> ，在我们的例子中， <img src="https://www.zhihu.com/equation?tex=1-%5Cvarepsilon%3D%5Cbeta%3D0.9" alt="1-\varepsilon=\beta=0.9"> ，即 <img src="https://www.zhihu.com/equation?tex=0.9%5E%7B10%7D%5Capprox+0.35%5Capprox%5Cdfrac%7B1%7D%7Be%7D" alt="0.9^{10}\approx 0.35\approx\dfrac{1}{e}"> 。相当于大约10天后，系数的峰值（这里是0.1）下降到原来的 <img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B1%7D%7Be%7D" alt="\dfrac{1}{e}"> ，只关注了过去10天的天气。</p>
<p><strong>指数加权平均实现</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=v_%7B0%7D+%3D0%5C%5C+v_%7B1%7D%3D+%5Cbeta+v_%7B0%7D%2B%281-%5Cbeta%29%5Ctheta_%7B1%7D%5C%5C+v_%7B2%7D%3D+%5Cbeta+v_%7B1%7D%2B%281-%5Cbeta%29%5Ctheta_%7B2%7D%5C%5C+v_%7B3%7D%3D+%5Cbeta+v_%7B2%7D%2B%281-%5Cbeta%29%5Ctheta_%7B3%7D%5C%5C+%5Cldots" alt="v_{0} =0\\ v_{1}= \beta v_{0}+(1-\beta)\theta_{1}\\ v_{2}= \beta v_{1}+(1-\beta)\theta_{2}\\ v_{3}= \beta v_{2}+(1-\beta)\theta_{3}\\ \ldots"></p>
<p>因为，在计算当前时刻的平均值，只需要前一天的平均值和当前时刻的值，所以在数据量非常大的情况下，指数加权平均在节约计算成本的方面是一种非常有效的方式，可以很大程度上减少计算机资源存储和内存的占用。</p>
<p><strong>指数加权平均的偏差修正</strong></p>
<p>在我们执行指数加权平均的公式时，当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D0.98" alt="\beta=0.98"> 时，我们得到的并不是图中的绿色曲线，而是下图中的紫色曲线，其起点比较低。</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-e52c3c3cebde2ec15f3f055fcbca7faa_hd.jpg" alt="img"></p>
<ul>
<li>原因：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=v_%7B0%7D%3D0%5C%5Cv_%7B1%7D%3D0.98v_%7B0%7D%2B0.02%5Ctheta_%7B1%7D%3D0.02%5Ctheta_%7B1%7D%5C%5Cv_%7B2%7D%3D0.98v_%7B1%7D%2B0.02%5Ctheta_%7B2%7D%3D0.98%5Ctimes0.02%5Ctheta_%7B1%7D%2B0.02%5Ctheta_%7B2%7D%3D0.0196%5Ctheta_%7B1%7D%2B0.02%5Ctheta_%7B2%7D" alt="v_{0}=0\\v_{1}=0.98v_{0}+0.02\theta_{1}=0.02\theta_{1}\\v_{2}=0.98v_{1}+0.02\theta_{2}=0.98\times0.02\theta_{1}+0.02\theta_{2}=0.0196\theta_{1}+0.02\theta_{2}"></p>
<p>如果第一天的值为如 <img src="https://www.zhihu.com/equation?tex=40" alt="40"> ，则 <img src="https://www.zhihu.com/equation?tex=v_%7B1%7D%3D0.02%5Ctimes40%3D8" alt="v_{1}=0.02\times40=8"> ，得到的值要远小于实际值，后面几天的情况也会由于初值引起的影响，均低于实际均值。</p>
<ul>
<li>偏差修正：</li>
</ul>
<p>使用 <img src="https://www.zhihu.com/equation?tex=v_%7B1%7D%3D0.02%5Ctimes40%3D8" alt="v_{1}=0.02\times40=8"></p>
<p>当 <img src="https://www.zhihu.com/equation?tex=t%3D2" alt="t=2"> 时：</p>
<p><img src="https://www.zhihu.com/equation?tex=+1-%5Cbeta%5E%7Bt%7D%3D1-%280.98%29%5E%7B2%7D%3D0.0396" alt=" 1-\beta^{t}=1-(0.98)^{2}=0.0396"></p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cdfrac%7Bv_%7B2%7D%7D%7B0.0396%7D%3D%5Cdfrac%7B0.0196%5Ctheta_%7B1%7D%2B0.02%5Ctheta_%7B2%7D%7D%7B0.0396%7D" alt=" \dfrac{v_{2}}{0.0396}=\dfrac{0.0196\theta_{1}+0.02\theta_{2}}{0.0396}"></p>
<p>偏差修正得到了绿色的曲线，在开始的时候，能够得到比紫色曲线更好的计算平均的效果。随着 <img src="https://www.zhihu.com/equation?tex=t" alt="t"> 逐渐增大， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%5E%7Bt%7D" alt="\beta^{t}"> 接近于0，所以后面绿色的曲线和紫色的曲线逐渐重合了。</p>
<p>虽然存在这种问题，但是在实际过程中，一般会忽略前期均值偏差的影响。</p>
<h2 id="3-动量（Momentum）梯度下降法"><a href="#3-动量（Momentum）梯度下降法" class="headerlink" title="3. 动量（Momentum）梯度下降法"></a><strong>3. 动量（Momentum）梯度下降法</strong></h2><p>动量梯度下降的基本思想就是计算梯度的指数加权平均数，并利用该梯度来更新权重。</p>
<p>在我们优化 Cost function 的时候，以下图所示的函数图为例：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-4e37ac10a00135412175a0ba85103035_hd.jpg" alt="img"></p>
<p>在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代。</p>
<p>如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率。</p>
<p>但是我们又希望在如图的纵轴方向梯度下降的缓慢一些，不要有如此大的上下波动，在横轴方向梯度下降的快速一些，使得能够更快的到达最小值点，而这里用动量梯度下降法既可以实现，如红色线所示。</p>
<p><strong>算法实现</strong></p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-070324bcdbf16b9104872c2a63b21e3b_hd.jpg" alt="img"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="\beta"> 常用的值是0.9。</p>
<p>在我们进行动量梯度下降算法的时候，由于使用了指数加权平均的方法。原来在纵轴方向上的上下波动，经过平均以后，接近于0，纵轴上的波动变得非常的小；但在横轴方向上，所有的微分都指向横轴方向，因此其平均值仍然很大。最终实现红色线所示的梯度下降曲线。</p>
<p><strong>算法本质解释</strong></p>
<p>在对应上面的计算公式中，将Cost function想象为一个碗状，想象从顶部往下滚球，其中：</p>
<ul>
<li>微分项 <img src="https://www.zhihu.com/equation?tex=dw%2Cdb" alt="dw,db"> 想象为球提供的加速度；</li>
<li>动量项 <img src="https://www.zhihu.com/equation?tex=v_%7Bdw%7D%2Cv_%7Bdb%7D" alt="v_{dw},v_{db}"> 相当于速度；</li>
</ul>
<p>小球在向下滚动的过程中，因为加速度的存在使得速度会变快，但是由于 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="\beta"> 的存在，其值小于1，可以认为是摩擦力，所以球不会无限加速下去。</p>
<h2 id="4-RMSprop"><a href="#4-RMSprop" class="headerlink" title="4. RMSprop"></a><strong>4. RMSprop</strong></h2><p>除了上面所说的<strong>Momentum</strong>梯度下降法，<strong>RMSprop</strong>（root mean square prop）也是一种可以加快梯度下降的算法。</p>
<p>同样算法的样例实现如下图所示：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-d9b0e716021f96c12ec478c8d4629b4f_hd.jpg" alt="img"></p>
<p>这里假设参数b的梯度处于纵轴方向，参数w的梯度处于横轴方向（当然实际中是处于高维度的情况），利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，如图中蓝色线所示，使其梯度下降的速度变得更快，如图绿色线所示。</p>
<p>在如图所示的实现中，RMSprop将微分项进行平方，然后使用平方根进行梯度更新，同时为了确保算法不会除以0，平方根分母中在实际使用会加入一个很小的值如 <img src="https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D10%5E%7B-8%7D" alt="\varepsilon=10^{-8}"> 。</p>
<h2 id="5-Adam-优化算法"><a href="#5-Adam-优化算法" class="headerlink" title="5. Adam 优化算法"></a><strong>5. Adam 优化算法</strong></h2><p>Adam （Adaptive Moment Estimation）优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法。</p>
<p><strong>算法实现</strong></p>
<ul>
<li><p>初始化： <img src="https://www.zhihu.com/equation?tex=V_%7Bdw%7D+%3D+0%EF%BC%8CS_%7Bdw%7D%3D0%EF%BC%8CV_%7Bdb%7D%3D0%EF%BC%8CS_%7Bdb%7D+%3D+0" alt="V_{dw} = 0，S_{dw}=0，V_{db}=0，S_{db} = 0"></p>
</li>
<li><p>第 <img src="https://www.zhihu.com/equation?tex=t" alt="t"> 次迭代：</p>
</li>
<li><ul>
<li>Compute <img src="https://www.zhihu.com/equation?tex=dw%EF%BC%8Cdb" alt="dw，db"> on the current mini-batch</li>
<li><img src="https://www.zhihu.com/equation?tex=V_%7Bdw%7D%3D%5Cbeta_%7B1%7DV_%7Bdw%7D%2B%281-%5Cbeta_%7B1%7D%29dw%EF%BC%8CV_%7Bdb%7D%3D%5Cbeta_%7B1%7DV_%7Bdb%7D%2B%281-%5Cbeta_%7B1%7D%29db" alt="V_{dw}=\beta_{1}V_{dw}+(1-\beta_{1})dw，V_{db}=\beta_{1}V_{db}+(1-\beta_{1})db"> —– “Momentum”</li>
<li><img src="https://www.zhihu.com/equation?tex=S_%7Bdw%7D%3D%5Cbeta_%7B2%7DS_%7Bdw%7D%2B%281-%5Cbeta_%7B2%7D%29%28dw%29%5E%7B2%7D%EF%BC%8CS_%7Bdb%7D%3D%5Cbeta_%7B2%7DS_%7Bdb%7D%2B%281-%5Cbeta_%7B2%7D%29%28db%29%5E%7B2%7D" alt="S_{dw}=\beta_{2}S_{dw}+(1-\beta_{2})(dw)^{2}，S_{db}=\beta_{2}S_{db}+(1-\beta_{2})(db)^{2}"> —– “RMSprop”</li>
<li><img src="https://www.zhihu.com/equation?tex=V_%7Bdw%7D%5E%7Bcorrected%7D+%3D+V_%7Bdw%7D%2F%281-%5Cbeta_%7B1%7D%5E%7Bt%7D%29%EF%BC%8CV_%7Bdb%7D%5E%7Bcorrected%7D+%3D+V_%7Bdb%7D%2F%281-%5Cbeta_%7B1%7D%5E%7Bt%7D%29" alt="V_{dw}^{corrected} = V_{dw}/(1-\beta_{1}^{t})，V_{db}^{corrected} = V_{db}/(1-\beta_{1}^{t})"> —– 偏差修正</li>
<li><img src="https://www.zhihu.com/equation?tex=S_%7Bdw%7D%5E%7Bcorrected%7D+%3D+S_%7Bdw%7D%2F%281-%5Cbeta_%7B2%7D%5E%7Bt%7D%29%EF%BC%8CS_%7Bdb%7D%5E%7Bcorrected%7D+%3D+S_%7Bdb%7D%2F%281-%5Cbeta_%7B2%7D%5E%7Bt%7D%29" alt="S_{dw}^{corrected} = S_{dw}/(1-\beta_{2}^{t})，S_{db}^{corrected} = S_{db}/(1-\beta_{2}^{t})"> —– 偏差修正</li>
<li><img src="https://www.zhihu.com/equation?tex=w%3A%3Dw-%5Calpha%5Cdfrac%7BV_%7Bdw%7D%5E%7Bcorrected%7D%7D%7B%5Csqrt%7BS_%7Bdw%7D%5E%7Bcorrected%7D%7D%2B%5Cvarepsilon%7D%EF%BC%8Cb%3A%3Db-%5Calpha%5Cdfrac%7BV_%7Bdb%7D%5E%7Bcorrected%7D%7D%7B%5Csqrt%7BS_%7Bdb%7D%5E%7Bcorrected%7D%7D%2B%5Cvarepsilon%7D" alt="w:=w-\alpha\dfrac{V_{dw}^{corrected}}{\sqrt{S_{dw}^{corrected}}+\varepsilon}，b:=b-\alpha\dfrac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\varepsilon}"></li>
</ul>
</li>
</ul>
<p><strong>超参数的选择</strong></p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="\alpha"> ：需要进行调试；</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Cbeta_%7B1%7D" alt="\beta_{1}"> ：常用缺省值为0.9， <img src="https://www.zhihu.com/equation?tex=dw" alt="dw"> 的加权平均；</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Cbeta_%7B2%7D" alt="\beta_{2}"> ：推荐使用0.999， <img src="https://www.zhihu.com/equation?tex=dw%5E%7B2%7D" alt="dw^{2}"> 的加权平均值；</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" alt="\varepsilon"> ：推荐使用 <img src="https://www.zhihu.com/equation?tex=10%5E%7B-8%7D" alt="10^{-8}"> 。</li>
</ul>
<h2 id="6-学习率衰减"><a href="#6-学习率衰减" class="headerlink" title="6. 学习率衰减"></a><strong>6. 学习率衰减</strong></h2><p>在我们利用 mini-batch 梯度下降法来寻找Cost function的最小值的时候，如果我们设置一个固定的学习速率 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="\alpha"> ，则算法在到达最小值点附近后，由于不同batch中存在一定的噪声，使得不会精确收敛，而一直会在一个最小值点较大的范围内波动，如下图中蓝色线所示。</p>
<p>但是如果我们使用学习率衰减，逐渐减小学习速率 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="\alpha"> ，在算法开始的时候，学习速率还是相对较快，能够相对快速的向最小值点的方向下降。但随着 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="\alpha"> 的减小，下降的步伐也会逐渐变小，最终会在最小值附近的一块更小的区域里波动，如图中绿色线所示。</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-0b54853b610c36c030c124606cea1d5c_hd.jpg" alt="img"></p>
<p><strong>学习率衰减的实现</strong></p>
<ul>
<li>常用： <img src="https://www.zhihu.com/equation?tex=%5Calpha+%3D+%5Cdfrac%7B1%7D%7B1%2Bdecay%5C_rate%2Aepoch%5C_num%7D%5Calpha_%7B0%7D" alt="\alpha = \dfrac{1}{1+decay\_rate*epoch\_num}\alpha_{0}"></li>
<li>指数衰减： <img src="https://www.zhihu.com/equation?tex=%5Calpha+%3D+0.95%5E%7Bepoch%5C_num%7D%5Calpha_%7B0%7D" alt="\alpha = 0.95^{epoch\_num}\alpha_{0}"></li>
<li>其他： <img src="https://www.zhihu.com/equation?tex=%5Calpha+%3D+%5Cdfrac%7Bk%7D%7Bepoch%5C_num%7D%5Ccdot%5Calpha_%7B0%7D" alt="\alpha = \dfrac{k}{epoch\_num}\cdot\alpha_{0}"></li>
<li>离散下降（不同阶段使用不同的学习速率）</li>
</ul>
<h2 id="7-局部最优问题"><a href="#7-局部最优问题" class="headerlink" title="7. 局部最优问题"></a><strong>7. 局部最优问题</strong></h2><p>在低维度的情形下，我们可能会想象到一个Cost function 如左图所示，存在一些局部最小值点，在初始化参数的时候，如果初始值选取的不得当，会存在陷入局部最优点的可能性。</p>
<p>但是，如果我们建立一个高维度的神经网络。通常梯度为零的点，并不是如左图中的局部最优点，而是右图中的<strong>鞍点</strong>（叫鞍点是因为其形状像马鞍的形状）。</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-ec0c95cf84b7d2ca878bcd51b4485707_hd.jpg" alt="img"></p>
<p>在一个具有高维度空间的函数中，如果梯度为0，那么在每个方向，Cost function可能是凸函数，也有可能是凹函数。但如果参数维度为2万维，想要得到局部最优解，那么所有维度均需要是凹函数，其概率为 <img src="https://www.zhihu.com/equation?tex=2%5E%7B-20000%7D" alt="2^{-20000}"> ，可能性非常的小。也就是说，在低维度中的局部最优点的情况，并不适用于高维度，在梯度为0的点更有可能是鞍点，而不是局部最小值点。</p>
<p>在高纬度的情况下：</p>
<ul>
<li>几乎不可能陷入局部最小值点；</li>
<li>处于鞍点的停滞区会减缓学习过程，利用如Adam等算法进行改善。</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/改善深层神经网络2/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-改善深层神经网络1" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/改善深层神经网络1/">深度学习的使用程面</a>
    </h1>
  

        
        <a href="/2018/02/05/改善深层神经网络1/" class="archive-article-date">
  	<time datetime="2018-02-05T08:34:37.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-训练、验证、测试集"><a href="#1-训练、验证、测试集" class="headerlink" title="1. 训练、验证、测试集"></a><strong>1. 训练、验证、测试集</strong></h2><p>对于一个需要解决的问题的样本数据，在建立模型的过程中，我们会将问题的<strong>data</strong>划分为以下几个部分：</p>
<ul>
<li>训练集（train set）：用训练集对算法或模型进行训练过程；</li>
<li>验证集（development set）：利用验证集或者又称为简单交叉验证集（hold-out cross validation set）进行交叉验证，选择出最好的模型；</li>
<li>测试集（test set）：最后利用测试集对模型进行测试，获取模型运行的无偏估计。</li>
</ul>
<p><strong>小数据时代：</strong></p>
<p>在小数据量的时代，如：100、1000、10000的数据量大小，可以将<strong>data</strong>做以下划分：</p>
<ul>
<li>无验证集的情况：70% / 30%；</li>
<li>有验证集的情况：60% / 20% / 20%；</li>
</ul>
<p>通常在小数据量时代，以上比例的划分是非常合理的。</p>
<p><strong>大数据时代：</strong></p>
<p>但是在如今的大数据时代，对于一个问题，我们拥有的<strong>data</strong>的数量可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。</p>
<p>验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大能够验证大约2-10种算法哪种更好就足够了，不需要使用20%的数据作为验证集。如百万数据中抽取1万的数据作为验证集就可以了。</p>
<p>测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中1000条数据足以评估单个模型的效果。</p>
<ul>
<li>100万数据量：98% / 1% / 1%；</li>
<li>超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）</li>
</ul>
<p><strong>Notation：</strong></p>
<ul>
<li>建议验证集和测试集来自于同一个分布，这样可以使得机器学习算法变得更快；</li>
<li>如果不需要用无偏估计来评估模型的性能，则可以不需要测试集。</li>
</ul>
<h2 id="2-偏差、方差"><a href="#2-偏差、方差" class="headerlink" title="2. 偏差、方差"></a><strong>2. 偏差、方差</strong></h2><p>对于下图中两个类别分类边界的分割：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-780fcc9466d6e335241727e0725c61fd_hd.jpg" alt="img"></p>
<p>从图中我们可以看出，在欠拟合（underfitting）的情况下，出现高偏差（high bias）的情况；在过拟合（overfitting）的情况下，出现高方差（high variance）的情况。</p>
<p>在 bias-variance tradeoff 的角度来讲，我们利用训练集对模型进行训练就是为了使得模型在train集上使 <strong>bias</strong>最小化，避免出现 underfitting 的情况；</p>
<p>但是如果模型设置的太复杂，虽然在train集上 bias 的值非常小，模型甚至可以将所有的数据点正确分类，但是当将训练好的模型应用在dev 集上的时候，却出现了较高的错误率。这是因为模型设置的太复杂则没有排除一些train集数据中的噪声，使得模型出现overfitting的情况，在dev 集上出现高<strong>variance</strong>的现象。</p>
<p>所以对于bias和variance的权衡问题，对于模型来说是一个十分重要的问题。</p>
<p><strong>例子：</strong></p>
<p>几种不同的情况：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-ef626d89314943c7701c0462fce443a9_hd.jpg" alt="img"></p>
<p>以上为在人眼判别误差在0%的情况下，该最优误差通常也称为“贝叶斯误差”，如果“贝叶斯误差”大约为15%，那么图中第二种情况就是一种比较好的情况。</p>
<p><strong>High bias and high variance的情况</strong></p>
<p>上图中第三种bias和variance的情况出现的可能如下：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-d31a17414aa07f477be2d1c94fb411ed_hd.jpg" alt="img"></p>
<p>没有找到边界线，但却在部分数据点上出现了过拟合，则会导致这种高偏差和高方差的情况。</p>
<p>虽然在这里二维的情况下可能看起来较为奇怪，出现的可能性比较低；但是在高维的情况下，出现这种情况就成为可能。</p>
<h2 id="3-机器学习的基本方法"><a href="#3-机器学习的基本方法" class="headerlink" title="3. 机器学习的基本方法"></a><strong>3. 机器学习的基本方法</strong></h2><p>在训练机器学习模型的过程中，解决High bias 和High variance 的过程：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-69ee1d22e22e3509ecd0f87554e7ba02_hd.jpg" alt="img"></p>
<ul>
<li><p>\1. 是否存在<strong>High bias</strong> ?</p>
</li>
<li><ul>
<li>增加网络结构，如增加隐藏层数目；</li>
<li>训练更长时间；</li>
<li>寻找合适的网络架构，使用更大的NN结构；</li>
</ul>
</li>
<li><p>\2. 是否存在<strong>High variance</strong>？</p>
</li>
<li><ul>
<li>获取更多的数据；</li>
<li>正则化（ regularization）；</li>
<li>寻找合适的网络结构；</li>
</ul>
</li>
</ul>
<p>在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以使得再不增加另一方的情况下减少一方的值。</p>
<h2 id="4-正则化（regularization）"><a href="#4-正则化（regularization）" class="headerlink" title="4. 正则化（regularization）"></a><strong>4. 正则化（regularization）</strong></h2><p>利用正则化来解决High variance 的问题，正则化是在 Cost function 中加入一项正则化项，惩罚模型的复杂度。</p>
<p><strong>Logistic regression</strong></p>
<p>加入正则化项的代价函数：</p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B2%7D%5E%7B2%7D" alt="J(w,b)=\dfrac{1}{m}\sum\limits_{i=1}^{m}l(\hat y^{(i)},y^{(i)})+\dfrac{\lambda}{2m}||w||_{2}^{2}"></p>
<p>上式为逻辑回归的L2正则化。</p>
<ul>
<li>L2正则化： <img src="http://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B2%7D%5E%7B2%7D+%3D+%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn_%7Bx%7D%7D+w_%7Bj%7D%5E%7B2%7D%3D%5Cdfrac%7B%5Clambda%7D%7B2m%7Dw%5E%7BT%7Dw" alt="\dfrac{\lambda}{2m}||w||_{2}^{2} = \dfrac{\lambda}{2m}\sum\limits_{j=1}^{n_{x}} w_{j}^{2}=\dfrac{\lambda}{2m}w^{T}w"></li>
<li>L1正则化： <img src="http://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B1%7D%3D%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn_%7Bx%7D%7D%7Cw_%7Bj%7D%7C" alt="\dfrac{\lambda}{2m}||w||_{1}=\dfrac{\lambda}{2m}\sum\limits_{j=1}^{n_{x}}|w_{j}|"></li>
</ul>
<p>其中 <img src="http://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda"> 为正则化因子。</p>
<p><strong>注意</strong>：<em>lambda </em>在python中属于保留字，所以在编程的时候，用“<strong>lambd</strong>”代表这里的正则化因子 <img src="http://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda"> 。</p>
<p><strong>Neural network</strong></p>
<p>加入正则化项的代价函数：</p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2Cw%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bl%3D1%7D%5E%7BL%7D%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D" alt="J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\dfrac{1}{m}\sum\limits_{i=1}^{m}l(\hat y^{(i)},y^{(i)})+\dfrac{\lambda}{2m}\sum\limits_{l=1}^{L}||w^{[l]}||_{F}^{2}"></p>
<p>其中 <img src="http://www.zhihu.com/equation?tex=%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D%3D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%5E%7B%5Bl-1%5D%7D%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn%5E%7B%5Bl%5D%7D%7D%28w_%7Bij%7D%5E%7B%5Bl%5D%7D%29%5E%7B2%7D" alt="||w^{[l]}||_{F}^{2}=\sum\limits_{i=1}^{n^{[l-1]}}\sum\limits_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^{2}"> ，因为 <img src="http://www.zhihu.com/equation?tex=w" alt="w"> 的大小为 <img src="http://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl-1%5D%7D%2Cn%5E%7B%5Bl%5D%7D%29" alt="(n^{[l-1]},n^{[l]})"> ，该矩阵范数被称为“Frobenius norm”</p>
<p><strong>Weight decay</strong></p>
<p>在加入正则化项后，梯度变为：</p>
<p><img src="http://www.zhihu.com/equation?tex=dW%5E%7B%5Bl%5D%7D+%3D+%28form%5C_backprop%29%2B%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D" alt="dW^{[l]} = (form\_backprop)+\dfrac{\lambda}{m}W^{[l]}"></p>
<p>则梯度更新公式变为：</p>
<p><img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3A%3D+W%5E%7B%5Bl%5D%7D-%5Calpha+dW%5E%7B%5Bl%5D%7D" alt="W^{[l]}:= W^{[l]}-\alpha dW^{[l]}"></p>
<p>代入可得：</p>
<p>![W^{[l]}:= W^{[l]}-\alpha [ (form_backprop)+\dfrac{\lambda}{m}W^{[l]}]\ = W^{[l]}-\alpha\dfrac{\lambda}{m}W^{[l]} -\alpha(form_backprop)\=(1-\dfrac{\alpha\lambda}{m})W^{<a href="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3A%3D+W%5E%7B%5Bl%5D%7D-%5Calpha+%5B+%28form%5C_backprop%29%2B%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D%5D%5C%5C+%3D+W%5E%7B%5Bl%5D%7D-%5Calpha%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D+-%5Calpha%28form%5C_backprop%29%5C%5C%3D%281-%5Cdfrac%7B%5Calpha%5Clambda%7D%7Bm%7D%29W%5E%7B%5Bl%5D%7D-%5Calpha%28form%5C_backprop%29" target="_blank" rel="noopener">l]}-\alpha(form_backprop)</a></p>
<p>其中， <img src="http://www.zhihu.com/equation?tex=%281-%5Cdfrac%7B%5Calpha%5Clambda%7D%7Bm%7D%29" alt="(1-\dfrac{\alpha\lambda}{m})"> 为一个 <img src="http://www.zhihu.com/equation?tex=%3C1" alt="&lt;1"> 的项，会给原来的 <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}">一个衰减的参数，所以<strong>L2范数正则化</strong>也被称为“权重衰减（Weight decay）”。</p>
<h2 id="5-为什么正则化可以减小过拟合"><a href="#5-为什么正则化可以减小过拟合" class="headerlink" title="5. 为什么正则化可以减小过拟合"></a><strong>5. 为什么正则化可以减小过拟合</strong></h2><p>假设下图的神经网络结构属于过拟合状态：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-62cbd6d66c8d7fb2da2d30ed5e80a9d1_hd.jpg" alt="img"></p>
<p>对于神经网络的 Cost function：</p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2Cw%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bl%3D1%7D%5E%7BL%7D%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D" alt="J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\dfrac{1}{m}\sum\limits_{i=1}^{m}l(\hat y^{(i)},y^{(i)})+\dfrac{\lambda}{2m}\sum\limits_{l=1}^{L}||w^{[l]}||_{F}^{2}"></p>
<p>加入正则化项，直观上理解，正则化因子 <img src="http://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda"> 设置的足够大的情况下，为了使代价函数最小化，权重矩阵 <img src="http://www.zhihu.com/equation?tex=W" alt="W"> 就会被设置为接近于0的值。则相当于消除了很多神经元的影响，那么图中的大的神经网络就会变成一个较小的网络。</p>
<p>当然上面这种解释是一种直观上的理解，但是实际上隐藏层的神经元依然存在，但是他们的影响变小了，便不会导致过拟合。</p>
<p><strong>数学解释：</strong></p>
<p>假设神经元中使用的激活函数为 <img src="http://www.zhihu.com/equation?tex=g%28z%29%3D%5Ctanh%28z%29" alt="g(z)=\tanh(z)"> ，在加入正则化项后：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-649a8466901387e1fdb2f5159fa676f4_hd.jpg" alt="img"></p>
<p>当 <img src="http://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda"> 增大，导致 <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> 减小， <img src="http://www.zhihu.com/equation?tex=Z%5E%7B%5Bl%5D%7D%3DW%5E%7B%5Bl%5D%7Da%5E%7B%5Bl-1%5D%7D%2Bb%5E%7B%5Bl%5D%7D" alt="Z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}"> 便会减小，由上图可知，在 <img src="http://www.zhihu.com/equation?tex=z" alt="z">较小的区域里， <img src="http://www.zhihu.com/equation?tex=%5Ctanh%28z%29" alt="\tanh(z)"> 函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，从而不会发生过拟合。</p>
<h2 id="6-Dropout-正则化"><a href="#6-Dropout-正则化" class="headerlink" title="6. Dropout 正则化"></a><strong>6. Dropout 正则化</strong></h2><p>Dropout（随机失活）就是在神经网络的Dropout层，为每个神经元结点设置一个随机消除的概率，对于保留下来的神经元，我们得到一个节点较少，规模较小的网络进行训练。</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-fa86d4f6c9fd6196859320bbaabba4df_hd.jpg" alt="img"></p>
<p><strong>实现Dropout的方法：</strong>反向随机失活（Inverted dropout）</p>
<p>首先假设对 layer 3 进行dropout：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = 0.8  # 设置神经元保留概率</span><br><span class="line">d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob</span><br><span class="line">a3 = np.multiply(a3, d3)</span><br><span class="line">a3 /= keep_prob</span><br></pre></td></tr></table></figure>
<p>这里解释下为什么要有最后一步：<strong>a3 /= keep_prob</strong></p>
<p>依照例子中的 keep_prob = 0.8 ，那么就有大约20%的神经元被删除了，也就是说 <img src="http://www.zhihu.com/equation?tex=a%5E%7B%5B3%5D%7D" alt="a^{[3]}"> 中有20%的元素被归零了，在下一层的计算中有 <img src="http://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D%3DW%5E%7B%5B4%5D%7D%5Ccdot+a%5E%7B%5B3%5D%7D%2Bb%5E%7B%5B4%5D%7D" alt="Z^{[4]}=W^{[4]}\cdot a^{[3]}+b^{[4]}"> ，所以为了不影响 <img src="http://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D" alt="Z^{[4]}"> 的期望值，所以需要 <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5B4%5D%7D%5Ccdot+a%5E%7B%5B3%5D%7D" alt="W^{[4]}\cdot a^{[3]}"> 的部分除以一个keep_prob。</p>
<p>Inverted dropout 通过对“a3 /= keep_prob”,则保证无论 keep_prob 设置为多少，都不会对 <img src="http://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D" alt="Z^{[4]}"> 的期望值产生影响。</p>
<p><strong>Notation：</strong>在测试阶段不要用dropout，因为那样会使得预测结果变得随机。</p>
<h2 id="7-理解-Dropout"><a href="#7-理解-Dropout" class="headerlink" title="7. 理解 Dropout"></a><strong>7. 理解 Dropout</strong></h2><p>另外一种对于Dropout的理解。</p>
<p>这里我们以单个神经元入手，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了Dropout以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。</p>
<p>所以通过传播过程，dropout将产生和L2范数相同的<strong>收缩权重</strong>的效果。</p>
<p>对于不同的层，设置的<strong>keep_prob</strong>也不同，一般来说神经元较少的层，会设 keep_prob</p>
<p>=1.0，神经元多的层，则会将keep_prob设置的较小。</p>
<p><strong>Dropout 缺点：</strong></p>
<p>dropout的一大缺点就是其使得 Cost function不能再被明确的定义，以为每次迭代都会随机消除一些神经元结点，所以我们无法绘制出每次迭代 <img src="http://www.zhihu.com/equation?tex=J%28W%2Cb%29" alt="J(W,b)"> 下降的图，如下：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-b766c408d994212d8eb7e198440be695_hd.jpg" alt="img"></p>
<p><strong>使用Dropout：</strong></p>
<ul>
<li>关闭dropout功能，即设置 keep_prob = 1.0；</li>
<li>运行代码，确保 <img src="http://www.zhihu.com/equation?tex=J%28W%EF%BC%8Cb%29" alt="J(W，b)"> 函数单调递减；</li>
<li>再打开 dropout 。</li>
</ul>
<h2 id="8-其他正则化方法"><a href="#8-其他正则化方法" class="headerlink" title="8. 其他正则化方法"></a><strong>8. 其他正则化方法</strong></h2><ul>
<li>数据扩增（Data augmentation）：通过图片的一些变换，得到更多的训练集和验证集；</li>
</ul>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-4ee8dd7e2fd0bfd2c5424994a59fcc98_hd.jpg" alt="img"></p>
<ul>
<li>Early stopping：在交叉验证集的误差上升之前的点停止迭代，避免过拟合。这种方法的缺点是无法同时解决bias和variance之间的最优。</li>
</ul>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-cdf222ea7b5b1fc8845f6e815395bd89_hd.jpg" alt="img"></p>
<h2 id="9-归一化输入"><a href="#9-归一化输入" class="headerlink" title="9. 归一化输入"></a><strong>9. 归一化输入</strong></h2><p>对数据集特征 <img src="http://www.zhihu.com/equation?tex=x_%7B1%7D%2Cx_%7B2%7D" alt="x_{1},x_{2}"> 归一化的过程：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-23cc05544f135c29429e7b0198079662_hd.jpg" alt="img"></p>
<ul>
<li>计算每个特征所有样本数据的均值： <img src="http://www.zhihu.com/equation?tex=%5Cmu+%3D+%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dx%5E%7B%28i%29%7D" alt="\mu = \dfrac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}"> ；</li>
<li>减去均值得到对称的分布： <img src="http://www.zhihu.com/equation?tex=x+%3A+%3Dx-%5Cmu" alt="x : =x-\mu"> ；</li>
<li>归一化方差： <img src="http://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D+%3D+%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dx%5E%7B%28i%29%5E%7B2%7D%7D" alt="\sigma^{2} = \dfrac{1}{m}\sum\limits_{i=1}^{m}x^{(i)^{2}}"> ， <img src="http://www.zhihu.com/equation?tex=x+%3D+x%2F%5Csigma%5E%7B2%7D" alt="x = x/\sigma^{2}"> 。</li>
</ul>
<p><strong>使用归一化的原因：</strong></p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-9b8ae9653968c8b956c4144577e75880_hd.jpg" alt="img"></p>
<p>由图可以看出不使用归一化和使用归一化前后 Cost function 的函数形状会有很大的区别。</p>
<p>在不使用归一化的代价函数中，如果我们设置一个较小的学习率，那么很可能我们需要很多次迭代才能到达代价函数全局最优解；如果使用了归一化，那么无论从哪个位置开始迭代，我们都能以相对很少的迭代次数找到全局最优解。</p>
<h2 id="10-梯度消失与梯度爆炸"><a href="#10-梯度消失与梯度爆炸" class="headerlink" title="10. 梯度消失与梯度爆炸"></a><strong>10. 梯度消失与梯度爆炸</strong></h2><p>如下图所示的神经网络结构，以两个输入为例：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-942dfd0140e24012549f9b1ca4e4d504_hd.jpg" alt="img"></p>
<p>这里我们首先假定 <img src="http://www.zhihu.com/equation?tex=g%28z%29+%3D+z%EF%BC%8Cb%5E%7B%5Bl%5D%7D%3D0" alt="g(z) = z，b^{[l]}=0"> ，所以对于目标输出有：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+W%5E%7B%5BL%5D%7DW%5E%7B%5BL-1%5D%7D%5Ccdots+W%5E%7B%5B2%5D%7DW%5E%7B%5B1%5D%7DX" alt="\hat y = W^{[L]}W^{[L-1]}\cdots W^{[2]}W^{[1]}X"></p>
<ul>
<li><img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> 的值大于1的情况：</li>
</ul>
<p>如： <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bl%7D1.5+%26+0+%5C%5C%5C+0+%26+1.5%5Cend%7Barray%7D+%5Cright%5D" alt="W^{[l]}=\left[ \begin{array}{l}1.5 &amp; 0 \\\ 0 &amp; 1.5\end{array} \right]"> ，那么最终， <img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+W%5E%7B%5BL%5D%7D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bl%7D1.5+%26+0+%5C%5C%5C+0+%26+1.5%5Cend%7Barray%7D+%5Cright%5D%5E%7BL-1%7DX" alt="\hat y = W^{[L]}\left[ \begin{array}{l}1.5 &amp; 0 \\\ 0 &amp; 1.5\end{array} \right]^{L-1}X"> ，激活函数的值将以指数级递增；</p>
<ul>
<li><img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> 的值小于1的情况：</li>
</ul>
<p>如： <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bl%7D0.5+%26+0+%5C%5C%5C+0+%26+0.5%5Cend%7Barray%7D+%5Cright%5D" alt="W^{[l]}=\left[ \begin{array}{l}0.5 &amp; 0 \\\ 0 &amp; 0.5\end{array} \right]"> ，那么最终， <img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+W%5E%7B%5BL%5D%7D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bl%7D0.5+%26+0+%5C%5C%5C+0+%26+0.5%5Cend%7Barray%7D+%5Cright%5D%5E%7BL-1%7DX" alt="\hat y = W^{[L]}\left[ \begin{array}{l}0.5 &amp; 0 \\\ 0 &amp; 0.5\end{array} \right]^{L-1}X"> ，激活函数的值将以指数级递减。</p>
<p>上面的情况对于导数也是同样的道理，所以在计算梯度时，根据情况的不同，梯度函数会以指数级递增或者递减，导致训练导数难度上升，梯度下降算法的步长会变得非常非常小，需要训练的时间将会非常长。</p>
<p>在梯度函数上出现的以指数级递增或者递减的情况就分别称为梯度爆炸或者梯度消失。</p>
<h2 id="11-利用初始化缓解梯度消失和爆炸问题"><a href="#11-利用初始化缓解梯度消失和爆炸问题" class="headerlink" title="11. 利用初始化缓解梯度消失和爆炸问题"></a><strong>11. 利用初始化缓解梯度消失和爆炸问题</strong></h2><p>以一个单个神经元为例子：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-a1783f8bfc4a2519275903658fdc44e8_hd.jpg" alt="img"></p>
<p>由上图可知，当输入的数量 <img src="http://www.zhihu.com/equation?tex=n" alt="n"> 较大时，我们希望每个 <img src="http://www.zhihu.com/equation?tex=w_%7Bi%7D" alt="w_{i}"> 的值都小一些，这样它们的和得到的 <img src="http://www.zhihu.com/equation?tex=z" alt="z"> 也较小。</p>
<p>这里为了得到较小的 <img src="http://www.zhihu.com/equation?tex=w_%7Bi%7D" alt="w_{i}"> ，设置 <img src="http://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B1%7D%7Bn%7D" alt="Var(w_{i})=\dfrac{1}{n}"> ，这里称为<strong>Xavier initialization。</strong></p>
<p>对参数进行初始化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WL = np.random.randn(WL.shape[0],WL.shape[1])* np.sqrt(1/n)</span><br></pre></td></tr></table></figure>
<p>这么做是因为，如果激活函数的输入 <img src="http://www.zhihu.com/equation?tex=x" alt="x"> 近似设置成均值为0，标准方差1的情况，输出 <img src="http://www.zhihu.com/equation?tex=z" alt="z"> 也会调整到相似的范围内。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。</p>
<p><strong>不同激活函数的 Xavier initialization：</strong></p>
<ul>
<li>激活函数使用Relu： <img src="http://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B2%7D%7Bn%7D" alt="Var(w_{i})=\dfrac{2}{n}"></li>
<li>激活函数使用tanh： <img src="http://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B1%7D%7Bn%7D" alt="Var(w_{i})=\dfrac{1}{n}"></li>
</ul>
<p>其中n是输入的神经元个数，也就是 <img src="http://www.zhihu.com/equation?tex=n%5E%7B%5Bl-1%5D%7D" alt="n^{[l-1]}"> 。</p>
<h2 id="12-梯度的数值逼近"><a href="#12-梯度的数值逼近" class="headerlink" title="12. 梯度的数值逼近"></a><strong>12. 梯度的数值逼近</strong></h2><p>使用双边误差的方法去逼近导数：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-2f23a8f5c12577d9dbaa2eb47b226e2d_hd.jpg" alt="img"></p>
<p>由图可以看出，双边误差逼近的误差是0.0001，先比单边逼近的误差0.03，其精度要高了很多。</p>
<p><strong>涉及的公式：</strong></p>
<ul>
<li>双边导数：</li>
</ul>
<p><img src="http://www.zhihu.com/equation?tex=f%27%28%5Ctheta%29+%3D+%5Clim%5Climits_%7B%5Cvarepsilon+%5Cto+0%7D%3D%5Cdfrac%7Bf%28%5Ctheta%2B%5Cvarepsilon%29-%28%5Ctheta-%5Cvarepsilon%29%7D%7B2%5Cvarepsilon%7D%5C%5C" alt="f&#39;(\theta) = \lim\limits_{\varepsilon \to 0}=\dfrac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2\varepsilon}\\"></p>
<p>误差： <img src="http://www.zhihu.com/equation?tex=O%28%5Cvarepsilon%5E%7B2%7D%29" alt="O(\varepsilon^{2})"></p>
<ul>
<li>单边导数：</li>
</ul>
<p><img src="http://www.zhihu.com/equation?tex=f%27%28%5Ctheta%29+%3D+%5Clim%5Climits_%7B%5Cvarepsilon+%5Cto+0%7D%3D%5Cdfrac%7Bf%28%5Ctheta%2B%5Cvarepsilon%29-%28%5Ctheta%29%7D%7B%5Cvarepsilon%7D%5C%5C+" alt="f&#39;(\theta) = \lim\limits_{\varepsilon \to 0}=\dfrac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}\\ "></p>
<p>误差： <img src="http://www.zhihu.com/equation?tex=O%28%5Cvarepsilon%29" alt="O(\varepsilon)"></p>
<h2 id="13-梯度检验"><a href="#13-梯度检验" class="headerlink" title="13. 梯度检验"></a><strong>13. 梯度检验</strong></h2><p>下面用前面一节的方法来进行梯度检验。</p>
<p><strong>连接参数：</strong></p>
<p>因为我们的神经网络中含有大量的参数： <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2CW%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D" alt="W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[L]}"> ，为了做梯度检验，需要将这些参数全部连接起来，reshape成一个大的向量 <img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta"> 。</p>
<p>同时对 <img src="http://www.zhihu.com/equation?tex=dW%5E%7B%5B1%5D%7D%2Cdb%5E%7B%5B1%5D%7D%2C%5Ccdots%2CdW%5E%7B%5BL%5D%7D%2Cdb%5E%7B%5BL%5D%7D" alt="dW^{[1]},db^{[1]},\cdots,dW^{[L]},db^{[L]}"> 执行同样的操作：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-4f422f204d09a055d4d4ed78d21a9437_hd.jpg" alt="img"></p>
<p><strong>进行梯度检验：</strong></p>
<p>进行如下图的梯度检验</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-9e1e6192fd6bb32ca0330c29a9d09688_hd.jpg" alt="img"></p>
<p>判断 <img src="http://www.zhihu.com/equation?tex=d%5Ctheta_%7Bapprox%7D%5Capprox+d%5Ctheta" alt="d\theta_{approx}\approx d\theta"> 是否接近。</p>
<p><strong>判断公式：</strong></p>
<p><img src="http://www.zhihu.com/equation?tex=%5Cdfrac+%7B%7C%7Cd%5Ctheta_%7Bapprox%7D-d%5Ctheta%7C%7C_%7B2%7D%7D%7B%7C%7Cd%5Ctheta_%7Bapprox%7D%7C%7C_%7B2%7D%2B%7C%7Cd%5Ctheta%7C%7C_%7B2%7D%7D" alt="\dfrac {||d\theta_{approx}-d\theta||_{2}}{||d\theta_{approx}||_{2}+||d\theta||_{2}}"></p>
<p>其中，“ <img src="http://www.zhihu.com/equation?tex=%7C%7C%5Ccdot+%7C%7C_%7B2%7D" alt="||\cdot ||_{2}"> ”表示欧几里得范数，它是误差平方之和，然后求平方根，得到的欧氏距离。</p>
<h2 id="14-实现梯度检验-Notes"><a href="#14-实现梯度检验-Notes" class="headerlink" title="14. 实现梯度检验 Notes"></a><strong>14. 实现梯度检验 Notes</strong></h2><ul>
<li>不要在训练过程中使用梯度检验，只在debug的时候使用，使用完毕关闭梯度检验的功能；</li>
<li>如果算法的梯度检验出现了错误，要检查每一项，找出错误，也就是说要找出哪个$d\theta_{approx}[i]$与$d\theta$的值相差比较大；</li>
<li>不要忘记了正则化项；</li>
<li>梯度检验不能与dropout同时使用。因为每次迭代的过程中，dropout会随机消除隐层单元的不同神经元，这时是难以计算dropout在梯度下降上的代价函数J；</li>
<li>在随机初始化的时候运行梯度检验，或许在训练几次后再进行。</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/改善深层神经网络1/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-神经网络和深度学习笔记4" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/神经网络和深度学习笔记4/">深层神经网络</a>
    </h1>
  

        
        <a href="/2018/02/05/神经网络和深度学习笔记4/" class="archive-article-date">
  	<time datetime="2018-02-05T08:31:47.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-矩阵的维度"><a href="#1-矩阵的维度" class="headerlink" title="1. 矩阵的维度"></a><strong>1. 矩阵的维度</strong></h2><p>DNN结构示意图如图所示：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-1b3bd333055cdfc4701fcb5de81311d4_hd.jpg" alt="img"></p>
<p>对于第 <img src="https://www.zhihu.com/equation?tex=l" alt="l"> 层神经网络，单个样本其各个参数的矩阵维度为：</p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2Cn%5E%7B%5Bl-1%5D%7D%29" alt="(n^{[l]},n^{[l-1]})"></li>
<li><img src="https://www.zhihu.com/equation?tex=b%5E%7B%5Bl%5D%7D" alt="b^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2C1%29" alt="(n^{[l]},1)"></li>
<li><img src="https://www.zhihu.com/equation?tex=dW%5E%7B%5Bl%5D%7D" alt="dW^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2Cn%5E%7B%5Bl-1%5D%7D%29" alt="(n^{[l]},n^{[l-1]})"></li>
<li><img src="https://www.zhihu.com/equation?tex=db%5E%7B%5Bl%5D%7D" alt="db^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2C1%29" alt="(n^{[l]},1)"></li>
<li><img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5Bl%5D%7D" alt="Z^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2C1%29" alt="(n^{[l]},1)"></li>
<li><img src="https://www.zhihu.com/equation?tex=A%5E%7B%5Bl%5D%7D%3DZ%5E%7B%5Bl%5D%7D" alt="A^{[l]}=Z^{[l]}"> ： <img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl%5D%7D%2C1%29" alt="(n^{[l]},1)"></li>
</ul>
<h2 id="2-为什么使用深层表示"><a href="#2-为什么使用深层表示" class="headerlink" title="2. 为什么使用深层表示"></a><strong>2. 为什么使用深层表示</strong></h2><p><strong>人脸识别和语音识别：</strong></p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-07b30fc02b2b2decaa66edcbff69f6b5_hd.jpg" alt="img"></p>
<p>对于人脸识别，神经网络的第一层从原始图片中提取人脸的轮廓和边缘，每个神经元学习到不同边缘的信息；网络的第二层将第一层学得的边缘信息组合起来，形成人脸的一些局部的特征，例如眼睛、嘴巴等；后面的几层逐步将上一层的特征组合起来，形成人脸的模样。随着神经网络层数的增加，特征也从原来的边缘逐步扩展为人脸的整体，由整体到局部，由简单到复杂。层数越多，那么模型学习的效果也就越精确。</p>
<p>对于语音识别，第一层神经网络可以学习到语言发音的一些音调，后面更深层次的网络可以检测到基本的音素，再到单词信息，逐渐加深可以学到短语、句子。</p>
<p>所以从上面的两个例子可以看出随着神经网络的深度加深，模型能学习到更加复杂的问题，功能也更加强大。</p>
<p><strong>电路逻辑计算：</strong></p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-d912f368562a4abdb0cf7b69589fdc64_hd.jpg" alt="img"></p>
<p>假定计算异或逻辑输出：</p>
<p><img src="https://www.zhihu.com/equation?tex=y%3Dx_%7B1%7D%5Coplus+x_%7B2%7D%5Coplus+x_%7B3%7D%5Coplus+%5Ccdots%5Coplus+x_%7Bn%7D" alt="y=x_{1}\oplus x_{2}\oplus x_{3}\oplus \cdots\oplus x_{n}"></p>
<p>对于该运算，若果使用深度神经网络，每层将前一层的相邻的两单元进行异或，最后到一个输出，此时整个网络的层数为一个树形的形状，网络的深度为 <img src="https://www.zhihu.com/equation?tex=O%28%5Clog_%7B2%7D%28n%29%29" alt="O(\log_{2}(n))"> ，共使用的神经元的个数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=1%2B2%2B%5Ccdot%2B2%5E%7B%5Clog_%7B2%7D%28n%29-1%7D%3D1%5Ccdot+%5Cdfrac%7B1-2%5E%7B%5Clog_%7B2%7D%28n%29%7D%7D%7B1-2%7D%3D2%5E%7B%5Clog_%7B2%7D%28n%29%7D-1%3Dn-1" alt="1+2+\cdot+2^{\log_{2}(n)-1}=1\cdot \dfrac{1-2^{\log_{2}(n)}}{1-2}=2^{\log_{2}(n)}-1=n-1"></p>
<p>即输入个数为n，输出个数为n-1。</p>
<p>但是如果不适用深层网络，仅仅使用单隐层的网络（如右图所示），需要的神经元个数为 <img src="https://www.zhihu.com/equation?tex=2%5E%7Bn-1%7D" alt="2^{n-1}"> 个 。同样的问题，但是深层网络要比浅层网络所需要的神经元个数要少得多。</p>
<h2 id="3-前向和反向传播"><a href="#3-前向和反向传播" class="headerlink" title="3. 前向和反向传播"></a><strong>3. 前向和反向传播</strong></h2><p>首先给定DNN的一些参数：</p>
<ul>
<li>L：DNN的总层数；</li>
<li><img src="https://www.zhihu.com/equation?tex=+n%5E%7B%5Bl%5D%7D" alt=" n^{[l]}">：表示第 <img src="https://www.zhihu.com/equation?tex=l" alt="l"> 层的包含的单元个数；</li>
<li><img src="https://www.zhihu.com/equation?tex=a%5E%7B%5Bl%5D%7D" alt="a^{[l]}"> ：表示第 <img src="https://www.zhihu.com/equation?tex=l" alt="l"> 层激活函数的输出；</li>
<li><img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> ：表示第 <img src="https://www.zhihu.com/equation?tex=l" alt="l"> 层的权重；</li>
<li>输入 <img src="https://www.zhihu.com/equation?tex=x" alt="x"> 记为 <img src="https://www.zhihu.com/equation?tex=a%5E%7B%5B0%5D%7D" alt="a^{[0]}"> ，输出 <img src="https://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 记为 <img src="https://www.zhihu.com/equation?tex=a%5E%7B%5BL%5D%7D" alt="a^{[L]}"> 。</li>
</ul>
<p><strong>前向传播（Forward propagation）</strong></p>
<p>Input： <img src="https://www.zhihu.com/equation?tex=a%5E%7B%5Bl-1%5D%7D" alt="a^{[l-1]}"></p>
<p>Output： <img src="https://www.zhihu.com/equation?tex=a%5E%7B%5Bl%5D%7D" alt="a^{[l]}"> ， <img src="https://www.zhihu.com/equation?tex=%5Crm+cache%28z%5E%7B%5Bl%5D%7D%29" alt="\rm cache(z^{[l]})"></p>
<ul>
<li>公式：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=z%5E%7B%5Bl%5D%7D%3D+W%5E%7B%5Bl%5D%7D%5Ccdot+a%5E%7B%5Bl-1%5D%7D%2Bb%5E%7B%5Bl%5D%7D%5C%5Ca%5E%7B%5Bl%5D%7D%3Dg%5E%7B%5Bl%5D%7D%28z%5E%7B%5Bl%5D%7D%29" alt="z^{[l]}= W^{[l]}\cdot a^{[l-1]}+b^{[l]}\\a^{[l]}=g^{[l]}(z^{[l]})"></p>
<ul>
<li>向量化程序：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5Bl%5D%7D%3DW%5E%7B%5Bl%5D%7D%5Ccdot+A%5E%7B%5Bl-1%5D%7D%2Bb%5E%7B%5Bl%5D%7D%5C%5CA%5E%7B%5Bl%5D%7D%3Dg%5E%7B%5Bl%5D%7D%28Z%5E%7B%5Bl%5D%7D%29" alt="Z^{[l]}=W^{[l]}\cdot A^{[l-1]}+b^{[l]}\\A^{[l]}=g^{[l]}(Z^{[l]})"></p>
<p><strong>反向传播（Backward propagation）</strong></p>
<p>Input： <img src="https://www.zhihu.com/equation?tex=da%5E%7B%5Bl%5D%7D" alt="da^{[l]}"></p>
<p>Output： <img src="https://www.zhihu.com/equation?tex=da%5E%7B%5Bl-1%5D%7D" alt="da^{[l-1]}"> ， <img src="https://www.zhihu.com/equation?tex=dW%5E%7B%5Bl%5D%7D" alt="dW^{[l]}"> ，<img src="https://www.zhihu.com/equation?tex=db%5E%7B%5Bl%5D%7D" alt="db^{[l]}"></p>
<ul>
<li>公式：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=dz%5E%7B%5Bl%5D%7D%3Dda%5E%7B%5Bl%5D%7D+%2A+g%5E%7B%5Bl%5D%7D%7B%27%7D%28z%5E%7B%5Bl%5D%7D%29%5C%5CdW%5E%7B%5Bl%5D%7D%3Ddz%5E%7B%5Bl%5D%7D%5Ccdot+a%5E%7B%5Bl-1%5D%7D%5C%5Cdb%5E%7B%5Bl%5D%7D%3Ddz%5E%7B%5Bl%5D%7D%5C%5Cda%5E%7B%5Bl-1%5D%7D%3DW%5E%7B%5Bl%5D%7D%7B%5ET%7D%5Ccdot+dz%5E%7B%5Bl%5D%7D" alt="dz^{[l]}=da^{[l]} * g^{[l]}{&#39;}(z^{[l]})\\dW^{[l]}=dz^{[l]}\cdot a^{[l-1]}\\db^{[l]}=dz^{[l]}\\da^{[l-1]}=W^{[l]}{^T}\cdot dz^{[l]}"></p>
<p>将 <img src="https://www.zhihu.com/equation?tex=da%5E%7B%5Bl-1%5D%7D+" alt="da^{[l-1]} "> 代入 <img src="https://www.zhihu.com/equation?tex=dz%5E%7B%5Bl%5D%7D" alt="dz^{[l]}"> ，有：</p>
<p><img src="https://www.zhihu.com/equation?tex=dz%5E%7B%5Bl%5D%7D%3DW%5E%7B%5Bl%2B1%5D%7D%7B%5ET%7D%5Ccdot+dz%5E%7B%5Bl%2B1%5D%7D%2A+g%5E%7B%5Bl%5D%7D%7B%27%7D%28z%5E%7B%5Bl%5D%7D%29%5C%5C" alt="dz^{[l]}=W^{[l+1]}{^T}\cdot dz^{[l+1]}* g^{[l]}{&#39;}(z^{[l]})\\"></p>
<ul>
<li>向量化程序：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=dZ%5E%7B%5Bl%5D%7D%3DdA%5E%7B%5Bl%5D%7D+%2A+g%5E%7B%5Bl%5D%7D%7B%27%7D%28Z%5E%7B%5Bl%5D%7D%29%5C%5CdW%5E%7B%5Bl%5D%7D%3D%5Cdfrac%7B1%7D%7Bm%7DdZ%5E%7B%5Bl%5D%7D%5Ccdot+A%5E%7B%5Bl-1%5D%7D%5C%5Cdb%5E%7B%5Bl%5D%7D%3D%5Cdfrac%7B1%7D%7Bm%7Dnp.sum%28dZ%5E%7B%5Bl%5D%7D%2Caxis%3D1%2Ckeepdims+%3D+True%29%5C%5CdA%5E%7B%5Bl-1%5D%7D%3DW%5E%7B%5Bl%5D%7D%7B%5ET%7D%5Ccdot+dZ%5E%7B%5Bl%5D%7D" alt="dZ^{[l]}=dA^{[l]} * g^{[l]}{&#39;}(Z^{[l]})\\dW^{[l]}=\dfrac{1}{m}dZ^{[l]}\cdot A^{[l-1]}\\db^{[l]}=\dfrac{1}{m}np.sum(dZ^{[l]},axis=1,keepdims = True)\\dA^{[l-1]}=W^{[l]}{^T}\cdot dZ^{[l]}"></p>
<h2 id="4-参数和超参数"><a href="#4-参数和超参数" class="headerlink" title="4. 参数和超参数"></a><strong>4. 参数和超参数</strong></h2><p><strong>参数：</strong></p>
<p>参数即是我们在过程中想要模型学习到的信息， <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> ， <img src="https://www.zhihu.com/equation?tex=b%5E%7B%5Bl%5D%7D" alt="b^{[l]}"> 。</p>
<p><strong>超参数：</strong></p>
<p>超参数即为控制参数的输出值的一些网络信息，也就是超参数的改变会导致最终得到的参数 <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="W^{[l]}"> ， <img src="https://www.zhihu.com/equation?tex=b%5E%7B%5Bl%5D%7D" alt="b^{[l]}"> 的改变。</p>
<p>举例：</p>
<ul>
<li>学习速率：<img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="\alpha"></li>
<li>迭代次数： <img src="https://www.zhihu.com/equation?tex=N" alt="N"></li>
<li>隐藏层的层数：<img src="https://www.zhihu.com/equation?tex=L+" alt="L "></li>
<li>每一层的神经元个数： <img src="https://www.zhihu.com/equation?tex=n%5E%7B%5B1%5D%7D" alt="n^{[1]}"> ， <img src="https://www.zhihu.com/equation?tex=n%5E%7B%5B2%5D%7D" alt="n^{[2]}"> , <img src="https://www.zhihu.com/equation?tex=%5Ccdots" alt="\cdots"></li>
<li>激活函数 <img src="https://www.zhihu.com/equation?tex=g%28z%29" alt="g(z)"> 的选择</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/神经网络和深度学习笔记4/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-神经网络和深度学习笔记3" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/神经网络和深度学习笔记3/">浅层神经网络</a>
    </h1>
  

        
        <a href="/2018/02/05/神经网络和深度学习笔记3/" class="archive-article-date">
  	<time datetime="2018-02-05T08:28:12.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-神经网络表示"><a href="#1-神经网络表示" class="headerlink" title="1. 神经网络表示"></a><strong>1. 神经网络表示</strong></h2><p>简单神经网络示意图：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-57166f7b5bb26904e62433ffffd01e61_hd.jpg" alt="img"></p>
<p>神经网络基本的结构和符号可以从上面的图中看出，这里不再复述。</p>
<p>主要需要注意的一点，是层与层之间参数矩阵的规格大小：</p>
<ul>
<li><p>输入层和隐藏层之间</p>
</li>
<li><ul>
<li><img src="http://www.zhihu.com/equation?tex=w%5E%7B%5B1%5D%7D-%3E%284%2C3%29" alt="w^{[1]}-&gt;(4,3)"> ：前面的4是隐层神经元的个数，后面的3是输入层神经元的个数；</li>
<li><img src="http://www.zhihu.com/equation?tex=b%5E%7B%5B1%5D%7D-%3E%284%2C1%29" alt="b^{[1]}-&gt;(4,1)"> ：和隐藏层的神经元个数相同；</li>
</ul>
</li>
<li><p>隐藏层和输出层之间</p>
</li>
<li><ul>
<li><img src="http://www.zhihu.com/equation?tex=w%5E%7B%5B1%5D%7D-%3E%281%2C4%29" alt="w^{[1]}-&gt;(1,4)"> ：前面的1是输出层神经元的个数，后面的4是隐层神经元的个数；</li>
<li><img src="http://www.zhihu.com/equation?tex=b%5E%7B%5B1%5D%7D-%3E%281%2C1%29" alt="b^{[1]}-&gt;(1,1)"> ：和输出层的神经元个数相同；</li>
</ul>
</li>
</ul>
<p>由上面我们可以总结出，在神经网络中，我们以相邻两层为观测对象，前面一层作为输入，后面一层作为输出，两层之间的w参数矩阵大小为 <img src="http://www.zhihu.com/equation?tex=%28n_%7Bout%7D%2Cn_%7Bin%7D%29" alt="(n_{out},n_{in})"> ，b参数矩阵大小为 <img src="http://www.zhihu.com/equation?tex=%28n_%7Bout%7D%2C1%29" alt="(n_{out},1)">，这里是作为 <img src="http://www.zhihu.com/equation?tex=z+%3D+wX%2Bb" alt="z = wX+b"> 的线性关系来说明的，在神经网络中， <img src="http://www.zhihu.com/equation?tex=w%5E%7B%5Bi%5D%7D%3Dw%5E%7BT%7D" alt="w^{[i]}=w^{T}"> 。</p>
<p>在logistic regression中，一般我们都会用 <img src="http://www.zhihu.com/equation?tex=%28n_%7Bin%7D%2Cn_%7Bout%7D%29" alt="(n_{in},n_{out})"> 来表示参数大小，计算使用的公式为： <img src="http://www.zhihu.com/equation?tex=z+%3D+w%5E%7BT%7DX%2Bb" alt="z = w^{T}X+b"> ，要注意这两者的区别。</p>
<h2 id="2-计算神经网络的输出"><a href="#2-计算神经网络的输出" class="headerlink" title="2. 计算神经网络的输出"></a><strong>2. 计算神经网络的输出</strong></h2><p>除输入层之外每层的计算输出可由下图总结出：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-6eb2bc22d2d7953ab4fb4115a2a33a96_hd.jpg" alt="img"></p>
<p>其中，每个结点都对应这两个部分的运算，z运算和a运算。 在编程中，我们使用向量化去计算神经网络的输出：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-6eb2bc22d2d7953ab4fb4115a2a33a96_hd.jpg" alt="img"></p>
<p>在对应图中的神经网络结构，我们只用Python代码去实现右边的四个公式即可实现神经网络的输出计算。</p>
<h2 id="3-向量化实现"><a href="#3-向量化实现" class="headerlink" title="3. 向量化实现"></a><strong>3. 向量化实现</strong></h2><p>假定在m个训练样本的神经网络中，计算神经网络的输出，用向量化的方法去实现可以避免在程序中使用for循环，提高计算的速度。</p>
<p>下面是实现向量化的解释：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-722991018136c95bff18be8e2932d987_hd.jpg" alt="img"></p>
<p>由图可以看出，在m个训练样本中，每次计算都是在重复相同的过程，均得到同样大小和结构的输出，所以利用向量化的思想将单个样本合并到一个矩阵中，其大小为 <img src="http://www.zhihu.com/equation?tex=%28x_%7Bn%7D%2Cm%29" alt="(x_{n},m)"> ，其中 <img src="http://www.zhihu.com/equation?tex=x_%7Bn%7D" alt="x_{n}"> 表示每个样本输入网络的神经元个数，也可以认为是单个样本的特征数，m表示训练样本的个数。</p>
<p>通过向量化，可以更加便捷快速地实现神经网络的计算。</p>
<h2 id="4-激活函数的选择"><a href="#4-激活函数的选择" class="headerlink" title="4. 激活函数的选择"></a><strong>4. 激活函数的选择</strong></h2><p>几种不同的激活函数 <img src="http://www.zhihu.com/equation?tex=g%28x%29" alt="g(x)"> ：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-58168196b7618a2dfe6b2f02a714fabb_hd.jpg" alt="img"></p>
<ul>
<li><p>sigmoid：<img src="http://www.zhihu.com/equation?tex=a+%3D+%5Cdfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt="a = \dfrac{1}{1+e^{-z}}"></p>
</li>
<li><ul>
<li>导数： <img src="http://www.zhihu.com/equation?tex=a%27+%3D+a%281-a%29" alt="a&#39; = a(1-a)"></li>
</ul>
</li>
<li><p>tanh： <img src="http://www.zhihu.com/equation?tex=a%3D%5Cdfrac%7Be%5E%7Bz%7D-e%5E%7B-z%7D%7D%7Be%5E%7Bz%7D%2Be%5E%7B-z%7D%7D" alt="a=\dfrac{e^{z}-e^{-z}}{e^{z}+e^{-z}}"></p>
</li>
<li><ul>
<li>导数：</li>
</ul>
</li>
<li><p>ReLU（修正线性单元）： <img src="http://www.zhihu.com/equation?tex=a+%3D+%5Cmax%280%2Cz%29" alt="a = \max(0,z)"></p>
</li>
<li><p>Leaky ReLU： <img src="http://www.zhihu.com/equation?tex=a+%3D+%5Cmax%280.01z%2Cz%29" alt="a = \max(0.01z,z)"></p>
</li>
</ul>
<p><strong>激活函数的选择：</strong></p>
<p>sigmoid函数和tanh函数比较：</p>
<ul>
<li>隐藏层：tanh函数的表现要好于sigmoid函数，因为tanh取值范围为 <img src="http://www.zhihu.com/equation?tex=%5B-1%2C%2B1%5D" alt="[-1,+1]"> ，输出分布在0值的附近，均值为0，从隐藏层到输出层数据起到了归一化（均值为0）的效果。</li>
<li>输出层：对于二分类任务的输出取值为 <img src="http://www.zhihu.com/equation?tex=%5C%7B0%2C1%5C%7D" alt="\{0,1\}"> ，故一般会选择sigmoid函数。</li>
</ul>
<p>然而sigmoid和tanh函数在当 <img src="http://www.zhihu.com/equation?tex=%7Cz%7C" alt="|z|"> 很大的时候，梯度会很小，在依据梯度的算法中，更新在后期会变得很慢。在实际应用中，要使 <img src="http://www.zhihu.com/equation?tex=%7Cz%7C" alt="|z|"> 尽可能的落在0值附近。</p>
<p>ReLU弥补了前两者的缺陷，当 <img src="http://www.zhihu.com/equation?tex=z%3E0" alt="z&gt;0"> 时，梯度始终为1，从而提高神经网络基于梯度算法的运算速度。然而当 <img src="http://www.zhihu.com/equation?tex=z%3C0" alt="z&lt;0"> 时，梯度一直为0，但是实际的运用中，该缺陷的影响不是很大。</p>
<p>Leaky ReLU保证在 <img src="http://www.zhihu.com/equation?tex=z%3C0" alt="z&lt;0"> 的时候，梯度仍然不为0。</p>
<p>在选择激活函数的时候，如果在不知道该选什么的时候就选择ReLU，当然也没有固定答案，要依据实际问题在交叉验证集合中进行验证分析。</p>
<h2 id="5-神经网络的梯度下降法"><a href="#5-神经网络的梯度下降法" class="headerlink" title="5. 神经网络的梯度下降法"></a><strong>5. 神经网络的梯度下降法</strong></h2><p>以本节中的浅层神经网络为例，我们给出神经网络的梯度下降法的公式。</p>
<ul>
<li>参数： <img src="http://www.zhihu.com/equation?tex=W%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2CW%5E%7B%5B2%5D%7D%2Cb%5E%7B%5B2%5D%7D" alt="W^{[1]},b^{[1]},W^{[2]},b^{[2]}"> ；</li>
<li>输入层特征向量个数： <img src="http://www.zhihu.com/equation?tex=n_%7Bx%7D%3Dn%5E%7B%5B0%5D%7D" alt="n_{x}=n^{[0]}"> ；</li>
<li>隐藏层神经元个数： <img src="http://www.zhihu.com/equation?tex=n%5E%7B%5B1%5D%7D" alt="n^{[1]}"> ；</li>
<li>输出层神经元个数： <img src="http://www.zhihu.com/equation?tex=n%5E%7B%5B2%5D%7D%3D1" alt="n^{[2]}=1"> ；</li>
<li><img src="http://www.zhihu.com/equation?tex=W%5E%7B%5B1%5D%7D" alt="W^{[1]}"> 的维度为 <img src="http://www.zhihu.com/equation?tex=%28n%5E%7B%5B1%5D%7D%2Cn%5E%7B%5B0%5D%7D%29" alt="(n^{[1]},n^{[0]})"> ， <img src="http://www.zhihu.com/equation?tex=b%5E%7B%5B1%5D%7D" alt="b^{[1]}"> 的维度为 <img src="http://www.zhihu.com/equation?tex=%28n%5E%7B%5B1%5D%7D%2C1%29" alt="(n^{[1]},1)"> ；</li>
<li><img src="http://www.zhihu.com/equation?tex=W%5E%7B%5B2%5D%7D" alt="W^{[2]}"> 的维度为 <img src="http://www.zhihu.com/equation?tex=%28n%5E%7B%5B2%5D%7D%2Cn%5E%7B%5B1%5D%7D%29" alt="(n^{[2]},n^{[1]})"> ， <img src="http://www.zhihu.com/equation?tex=b%5E%7B%5B2%5D%7D" alt="b^{[2]}"> 的维度为 <img src="http://www.zhihu.com/equation?tex=%28n%5E%7B%5B2%5D%7D%2C1%29" alt="(n^{[2]},1)"> ；</li>
</ul>
<p>下面为该例子的神经网络反向梯度下降公式（左）和其代码向量化（右）：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-88e08b98b1d6ee1acba5f79a326fbb82_hd.jpg" alt="img"></p>
<h2 id="6-随机初始化"><a href="#6-随机初始化" class="headerlink" title="6. 随机初始化"></a><strong>6. 随机初始化</strong></h2><p>如果在初始时，两个隐藏神经元的参数设置为相同的大小，那么两个隐藏神经元对输出单元的影响也是相同的，通过反向梯度下降去进行计算的时候，会得到同样的梯度大小，所以在经过多次迭代后，两个隐藏层单位仍然是对称的。无论设置多少个隐藏单元，其最终的影响都是相同的，那么多个隐藏神经元就没有了意义。</p>
<p>在初始化的时候， <img src="http://www.zhihu.com/equation?tex=W" alt="W"> 参数要进行随机初始化， <img src="http://www.zhihu.com/equation?tex=b" alt="b"> 则不存在对称性的问题它可以设置为0。 以2个输入，2个隐藏神经元为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W = np.random.rand((2,2))* 0.01</span><br><span class="line">b = np.zero((2,1))</span><br></pre></td></tr></table></figure>
<p>这里我们将W的值乘以0.01是为了尽可能使得权重W初始化为较小的值，这是因为如果使用sigmoid函数或者tanh函数作为激活函数时，W比较小，则 <img src="http://www.zhihu.com/equation?tex=Z+%3D+WX%2Bb" alt="Z = WX+b"> 所得的值也比较小，处在0的附近，0点区域的附近梯度较大，能够大大提高算法的更新速度。而如果W设置的太大的话，得到的梯度较小，训练过程因此会变得很慢。</p>
<p>ReLU和Leaky ReLU作为激活函数时，不存在这种问题，因为在大于0的时候，梯度均为1。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/神经网络和深度学习笔记3/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-神经网络和深度学习笔记2" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/神经网络和深度学习笔记2/">神经网络编程基础</a>
    </h1>
  

        
        <a href="/2018/02/05/神经网络和深度学习笔记2/" class="archive-article-date">
  	<time datetime="2018-02-05T08:22:34.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-二分类问题"><a href="#1-二分类问题" class="headerlink" title="1. 二分类问题"></a><strong>1. 二分类问题</strong></h2><p>对于二分类问题，大牛给出了一个小的Notation。</p>
<ul>
<li>样本： <img src="http://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="(x,y)"> ，训练样本包含 <img src="http://www.zhihu.com/equation?tex=m" alt="m"> 个；</li>
<li>其中 <img src="http://www.zhihu.com/equation?tex=x%5Cin+R%5E%7Bn_%7Bx%7D%7D" alt="x\in R^{n_{x}}"> ，表示样本<img src="http://www.zhihu.com/equation?tex=x+" alt="x "> 包含 <img src="http://www.zhihu.com/equation?tex=n_%7Bx%7D" alt="n_{x}">个特征；</li>
<li><img src="http://www.zhihu.com/equation?tex=y%5Cin%7B0%2C1%7D" alt="y\in{0,1}"> ，目标值属于0、1分类；</li>
<li>训练数据： <img src="http://www.zhihu.com/equation?tex=%5C%7B%28x%5E%7B%281%29%7D%2Cy%5E%7B%281%29%7D%29%2C%28x%5E%7B%282%29%7D%2Cy%5E%7B%282%29%7D%29%2C%5Ccdots%2C%28x%5E%7B%28m%29%7D%2Cy%5E%7B%28m%29%7D%29%5C%7D" alt="\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)})\}"></li>
</ul>
<p>输入神经网络时样本数据的形状：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-e5174ac94060bf4f290ddd13fa69bc58_hd.jpg" alt="img"></p>
<p><img src="http://www.zhihu.com/equation?tex=X.shape%3D%28n_%7Bx%7D%2C+m%29" alt="X.shape=(n_{x}, m)"></p>
<p>目标数据的形状：</p>
<p><img src="http://www.zhihu.com/equation?tex=Y%3D%5By_%7B%281%29%7D%2Cy_%7B%282%29%7D%2C%5Ccdots%2Cy_%7B%28m%29%7D%5D+" alt="Y=[y_{(1)},y_{(2)},\cdots,y_{(m)}] "></p>
<p><img src="http://www.zhihu.com/equation?tex=Y.shape%3D%281%2C+m%29" alt="Y.shape=(1, m)"></p>
<h2 id="2-logistic-Regression"><a href="#2-logistic-Regression" class="headerlink" title="2. logistic Regression"></a><strong>2. logistic Regression</strong></h2><p>逻辑回归中，预测值：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5C%5B%5Chat+h+%3D+P%28y%3D1%7Cx%29%5C%5D" alt="\[\hat h = P(y=1|x)\]"></p>
<p>其表示为1的概率，取值范围在 <img src="http://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]"> 之间。 引入Sigmoid函数，预测值：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+Sigmoid%28w%5E%7BT%7Dx%2Bb%29%3D%5Csigma%28w%5E%7BT%7Dx%2Bb%29" alt="\hat y = Sigmoid(w^{T}x+b)=\sigma(w^{T}x+b)"></p>
<p>其中</p>
<p><img src="http://www.zhihu.com/equation?tex=+Sigmoid%28z%29%3D%5Cdfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt=" Sigmoid(z)=\dfrac{1}{1+e^{-z}}"></p>
<p><strong>注意点：</strong>函数的一阶导数可以用其自身表示，</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Csigma%27%28z%29%3D%5Csigma%28z%29%281-%5Csigma%28z%29%29" alt="\sigma&#39;(z)=\sigma(z)(1-\sigma(z))"></p>
<p>这里可以解释梯度消失的问题，当 <img src="http://www.zhihu.com/equation?tex=z%3D0" alt="z=0"> 时，导数最大，但是导数最大为 <img src="http://www.zhihu.com/equation?tex=%5Csigma%27%280%29%3D%5Csigma%280%29%281-%5Csigma%280%29%29%3D0.5%281-0.5%29%3D0.25" alt="\sigma&#39;(0)=\sigma(0)(1-\sigma(0))=0.5(1-0.5)=0.25"> ，这里导数仅为原函数值的0.25倍。 参数梯度下降公式的不断更新， <img src="http://www.zhihu.com/equation?tex=%5Csigma%27%28z%29" alt="\sigma&#39;(z)"> 会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。</p>
<h2 id="2-logistic-Regression-1"><a href="#2-logistic-Regression-1" class="headerlink" title="2. logistic Regression"></a><strong>2. logistic Regression</strong></h2><p>逻辑回归中，预测值：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5C%5B%5Chat+h+%3D+P%28y%3D1%7Cx%29%5C%5D" alt="\[\hat h = P(y=1|x)\]"></p>
<p>其表示为1的概率，取值范围在 <img src="http://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]"> 之间。 引入Sigmoid函数，预测值：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+Sigmoid%28w%5E%7BT%7Dx%2Bb%29%3D%5Csigma%28w%5E%7BT%7Dx%2Bb%29" alt="\hat y = Sigmoid(w^{T}x+b)=\sigma(w^{T}x+b)"></p>
<p>其中</p>
<p><img src="http://www.zhihu.com/equation?tex=+Sigmoid%28z%29%3D%5Cdfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt=" Sigmoid(z)=\dfrac{1}{1+e^{-z}}"></p>
<p><strong>注意点：</strong>函数的一阶导数可以用其自身表示，</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Csigma%27%28z%29%3D%5Csigma%28z%29%281-%5Csigma%28z%29%29" alt="\sigma&#39;(z)=\sigma(z)(1-\sigma(z))"></p>
<p>这里可以解释梯度消失的问题，当 <img src="http://www.zhihu.com/equation?tex=z%3D0" alt="z=0"> 时，导数最大，但是导数最大为 <img src="http://www.zhihu.com/equation?tex=%5Csigma%27%280%29%3D%5Csigma%280%29%281-%5Csigma%280%29%29%3D0.5%281-0.5%29%3D0.25" alt="\sigma&#39;(0)=\sigma(0)(1-\sigma(0))=0.5(1-0.5)=0.25"> ，这里导数仅为原函数值的0.25倍。 参数梯度下降公式的不断更新， <img src="http://www.zhihu.com/equation?tex=%5Csigma%27%28z%29" alt="\sigma&#39;(z)"> 会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。</p>
<h2 id="3-logistic回归-损失函数"><a href="#3-logistic回归-损失函数" class="headerlink" title="3. logistic回归 损失函数"></a><strong>3. logistic回归 损失函数</strong></h2><p><strong>Loss function</strong></p>
<p>一般经验来说，使用平方错误（squared error）来衡量Loss Function：</p>
<p><img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29%3D%5Cdfrac%7B1%7D%7B2%7D%28%5Chat+y-y%29%5E%7B2%7D" alt="L(\hat y, y)=\dfrac{1}{2}(\hat y-y)^{2}"></p>
<p>但是，对于logistic regression 来说，一般不适用平方错误来作为Loss Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。</p>
<p>逻辑回归的Loss Function：</p>
<p><img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29%3D-%28y%5Clog%5Chat+y%2B%281-y%29%5Clog%281-%5Chat+y%29%29" alt="L(\hat y, y)=-(y\log\hat y+(1-y)\log(1-\hat y))"></p>
<ul>
<li>当 <img src="http://www.zhihu.com/equation?tex=y%3D1" alt="y=1"> 时， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29%3D-%5Clog+%5Chat+y" alt="L(\hat y, y)=-\log \hat y"> 。如果 <img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 越接近1， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29+%5Capprox+0" alt="L(\hat y, y) \approx 0"> ，表示预测效果越好；如果 <img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 越接近0， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29+%5Capprox+%2B%5Cinfty" alt="L(\hat y, y) \approx +\infty"> ，表示预测效果越差；</li>
<li>当 <img src="http://www.zhihu.com/equation?tex=y%3D0" alt="y=0"> 时， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29%3D-%5Clog+%281-%5Chat+y%29" alt="L(\hat y, y)=-\log (1-\hat y)"> 。如果 <img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 越接近0， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29+%5Capprox+0" alt="L(\hat y, y) \approx 0"> ，表示预测效果越好；如果 <img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 越接近1， <img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29+%5Capprox+%2B%5Cinfty" alt="L(\hat y, y) \approx +\infty"> ，表示预测效果越差；</li>
<li>我们的目标是最小化样本点的损失Loss Function，损失函数是针对单个样本点的。</li>
</ul>
<p><strong>Cost function</strong></p>
<p>全部训练数据集的Loss function总和的平均值即为训练集的代价函数（Cost function）。</p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7DL%28%5Chat+y%5E%7B%28i%29%7D%2C+y%5E%7B%28i%29%7D%29%3D-%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%5By%5E%7B%28i%29%7D%5Clog%5Chat+y%5E%7B%28i%29%7D%2B%281-y%5E%7B%28i%29%7D%29%5Clog%281-%5Chat+y%5E%7B%28i%29%7D%29%5Cright%5D" alt="J(w,b)=\dfrac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum_{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]"></p>
<ul>
<li>Cost function是待求系数w和b的函数；</li>
<li>我们的目标就是迭代计算出最佳的w和b的值，最小化Cost function，让其尽可能地接近于0。</li>
</ul>
<h2 id="4-梯度下降"><a href="#4-梯度下降" class="headerlink" title="4. 梯度下降"></a><strong>4. 梯度下降</strong></h2><p>用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。</p>
<p>每次迭代更新的修正表达式：</p>
<p><img src="http://www.zhihu.com/equation?tex=w%3A%3Dw-%5Calpha%5Cdfrac%7B%5Cpartial+J%28w%2Cb%29%7D%7B%5Cpartial+w%7D" alt="w:=w-\alpha\dfrac{\partial J(w,b)}{\partial w}"></p>
<p><img src="http://www.zhihu.com/equation?tex=b%3A%3Db-%5Calpha%5Cdfrac%7B%5Cpartial+J%28w%2Cb%29%7D%7B%5Cpartial+b%7D" alt="b:=b-\alpha\dfrac{\partial J(w,b)}{\partial b}"></p>
<p>在程序代码中，我们通常使用dw来表示 <img src="http://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+J%28w%2Cb%29%7D%7B%5Cpartial+w%7D" alt="\dfrac{\partial J(w,b)}{\partial w}"> ，用db来表示 <img src="http://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+J%28w%2Cb%29%7D%7B%5Cpartial+b%7D" alt="\dfrac{\partial J(w,b)}{\partial b}"> 。</p>
<h2 id="5-逻辑回归中的梯度下降法"><a href="#5-逻辑回归中的梯度下降法" class="headerlink" title="5. 逻辑回归中的梯度下降法"></a><strong>5. 逻辑回归中的梯度下降法</strong></h2><p>对单个样本而言，逻辑回归Loss function表达式：</p>
<p><img src="http://www.zhihu.com/equation?tex=z%3D+w%5E%7BT%7Dx%2Bb" alt="z= w^{T}x+b"></p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y%3Da%3D%5Csigma%28z%29" alt="\hat y=a=\sigma(z)"></p>
<p><img src="http://www.zhihu.com/equation?tex=L%28a%2C+y%29%3D-%28y%5Clog+%28a%29%2B%281-y%29%5Clog%281-a%29%29" alt="L(a, y)=-(y\log (a)+(1-y)\log(1-a))"></p>
<p>反向传播过程：</p>
<p><img src="http://p3ev46x16.bkt.clouddn.com/v2-fb5821785005d813809522a1a7108f7e_hd.jpg" alt="img"></p>
<p>前面过程的da、dz求导：</p>
<p><img src="http://www.zhihu.com/equation?tex=da+%3D+%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%7D%3D-%5Cdfrac%7By%7D%7Ba%7D%2B%5Cdfrac%7B1-y%7D%7B1-a%7D" alt="da = \dfrac{\partial L}{\partial a}=-\dfrac{y}{a}+\dfrac{1-y}{1-a}"></p>
<p><img src="http://www.zhihu.com/equation?tex=dz+%3D+%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%7D%3D%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%7D%5Ccdot%5Cdfrac%7B%5Cpartial+a%7D%7B%5Cpartial+z%7D%3D%28-%5Cdfrac%7By%7D%7Ba%7D%2B%5Cdfrac%7B1-y%7D%7B1-a%7D%29%5Ccdot+a%281-a%29%3Da-y" alt="dz = \dfrac{\partial L}{\partial z}=\dfrac{\partial L}{\partial a}\cdot\dfrac{\partial a}{\partial z}=(-\dfrac{y}{a}+\dfrac{1-y}{1-a})\cdot a(1-a)=a-y"></p>
<p>再对 <img src="http://www.zhihu.com/equation?tex=w_%7B1%7D%E3%80%81w_%7B2%7D" alt="w_{1}、w_{2}"> 和b进行求导：</p>
<p><img src="http://www.zhihu.com/equation?tex=dw_%7B1%7D+%3D+%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+w_%7B1%7D%7D%3D%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%7D%5Ccdot%5Cdfrac%7B%5Cpartial+z%7D%7B%5Cpartial+w_%7B1%7D%7D%3Dx_%7B1%7D%5Ccdot+dz%3Dx_%7B1%7D%28a-y%29" alt="dw_{1} = \dfrac{\partial L}{\partial w_{1}}=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial w_{1}}=x_{1}\cdot dz=x_{1}(a-y)"></p>
<p><img src="http://www.zhihu.com/equation?tex=db+%3D+%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+b+%7D%3D%5Cdfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%7D%5Ccdot%5Cdfrac%7B%5Cpartial+z%7D%7B%5Cpartial+b+%7D%3D1%5Ccdot+dz%3Da-y" alt="db = \dfrac{\partial L}{\partial b }=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial b }=1\cdot dz=a-y"></p>
<p>梯度下降法：</p>
<p><img src="http://www.zhihu.com/equation?tex=w_%7B1%7D%3A%3Dw_%7B1%7D-%5Calpha+dw_%7B1%7D" alt="w_{1}:=w_{1}-\alpha dw_{1}"></p>
<p><img src="http://www.zhihu.com/equation?tex=w_%7B2%7D%3A%3Dw_%7B2%7D-%5Calpha+dw_%7B2%7D" alt="w_{2}:=w_{2}-\alpha dw_{2}"></p>
<p><img src="http://www.zhihu.com/equation?tex=b%3A%3Db-%5Calpha+db" alt="b:=b-\alpha db"></p>
<h2 id="6-m个样本的梯度下降"><a href="#6-m个样本的梯度下降" class="headerlink" title="6. m个样本的梯度下降"></a><strong>6. m个样本的梯度下降</strong></h2><p>对m个样本来说，其Cost function表达式如下：</p>
<p><img src="http://www.zhihu.com/equation?tex=z%5E%7B%28i%29%7D%3D+w%5E%7BT%7Dx%5E%7B%28i%29%7D%2Bb" alt="z^{(i)}= w^{T}x^{(i)}+b"></p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y%5E%7B%28i%29%7D%3Da%5E%7B%28i%29%7D%3D%5Csigma%28z%5E%7B%28i%29%7D%29" alt="\hat y^{(i)}=a^{(i)}=\sigma(z^{(i)})"></p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7DL%28%5Chat+y%5E%7B%28i%29%7D%2C+y%5E%7B%28i%29%7D%29%3D-%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%5By%5E%7B%28i%29%7D%5Clog%5Chat+y%5E%7B%28i%29%7D%2B%281-y%5E%7B%28i%29%7D%29%5Clog%281-%5Chat+y%5E%7B%28i%29%7D%29%5Cright%5D" alt="J(w,b)=\dfrac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum_{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]"></p>
<p>Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式：</p>
<p><img src="http://www.zhihu.com/equation?tex=dw_%7B1%7D+%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7Dx_%7B1%7D%5E%7B%28i%29%7D%28a%5E%7B%28i%29%7D-y%5E%7B%28i%29%7D%29" alt="dw_{1} =\dfrac{1}{m}\sum_{i=1}^{m}x_{1}^{(i)}(a^{(i)}-y^{(i)})"></p>
<p><img src="http://www.zhihu.com/equation?tex=db+%3D+%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28a%5E%7B%28i%29%7D-y%5E%7B%28i%29%7D%29" alt="db = \dfrac{1}{m}\sum_{i=1}^{m}(a^{(i)}-y^{(i)})"></p>
<h2 id="7-向量化（Vectorization）"><a href="#7-向量化（Vectorization）" class="headerlink" title="7. 向量化（Vectorization）"></a><strong>7. 向量化（Vectorization）</strong></h2><p>在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。</p>
<p><strong>逻辑回归向量化</strong></p>
<ul>
<li>输入矩阵X：<img src="http://www.zhihu.com/equation?tex=%28n_%7Bx%7D%2Cm%29" alt="(n_{x},m)"></li>
<li>权重矩阵w： <img src="http://www.zhihu.com/equation?tex=%28n_%7Bx%7D%2C1%29" alt="(n_{x},1)"></li>
<li>偏置b：为一个常数</li>
<li>输出矩阵Y： <img src="http://www.zhihu.com/equation?tex=%281%2Cm%29" alt="(1,m)"></li>
</ul>
<p>所有m个样本的线性输出Z可以用矩阵表示：</p>
<p><img src="http://www.zhihu.com/equation?tex=Z+%3D+w%5E%7BT%7DX%2Bb" alt="Z = w^{T}X+b"></p>
<p>python代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db = 1/m*np.sum(dZ)</span><br></pre></td></tr></table></figure>
<p><strong>单次迭代梯度下降算法流程</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Z = np.dot(w.T,X) + b</span><br><span class="line">A = sigmoid(Z)</span><br><span class="line">dZ = A-Y</span><br><span class="line">dw = 1/m*np.dot(X,dZ.T)</span><br><span class="line">db = 1/m*np.sum(dZ)</span><br><span class="line"></span><br><span class="line">w = w - alpha*dw</span><br><span class="line">b = b - alpha*db</span><br></pre></td></tr></table></figure>
<h2 id="8-python的notation"><a href="#8-python的notation" class="headerlink" title="8. python的notation"></a><strong>8. python的notation</strong></h2><p>虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；</p>
<p>如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(5)</span><br></pre></td></tr></table></figure>
<p>如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(5,1)</span><br><span class="line">b = np.random.randn(1,5)</span><br></pre></td></tr></table></figure>
<p>可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert(a.shape == (5,1))</span><br></pre></td></tr></table></figure>
<p>可以使用reshape函数对数组设定所需的维度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.reshape((5,1))</span><br></pre></td></tr></table></figure>
<h2 id="8-logistic-regression代价函数的解释"><a href="#8-logistic-regression代价函数的解释" class="headerlink" title="8. logistic regression代价函数的解释"></a><strong>8. logistic regression代价函数的解释</strong></h2><p><strong>Cost function的由来</strong></p>
<p>预测输出 <img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 的表达式：</p>
<p><img src="http://www.zhihu.com/equation?tex=+%5Chat+y+%3D%5Csigma%28w%5E%7BT%7Dx%2Bb%29" alt=" \hat y =\sigma(w^{T}x+b)"></p>
<p>其中， <img src="http://www.zhihu.com/equation?tex=%5Csigma%28z%29%3D%5Cdfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt="\sigma(z)=\dfrac{1}{1+e^{-z}}"> 。</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y" alt="\hat y"> 可以看作预测输出为正类（+1）的概率：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Chat+y+%3D+P%28y%3D1%7Cx%29" alt="\hat y = P(y=1|x)"></p>
<p>当 <img src="http://www.zhihu.com/equation?tex=y%3D1" alt="y=1"> 时， <img src="http://www.zhihu.com/equation?tex=P%28y%7Cx%29%3D%5Chat+y" alt="P(y|x)=\hat y"> ；当 <img src="http://www.zhihu.com/equation?tex=y%3D0" alt="y=0"> 时， <img src="http://www.zhihu.com/equation?tex=P%28y%7Cx%29%3D1-%5Chat+y" alt="P(y|x)=1-\hat y"> 。</p>
<p>将两种情况整合到一个式子中，可得：</p>
<p><img src="http://www.zhihu.com/equation?tex=P%28y%7Cx%29%3D%5Chat+y%5E%7By%7D%281-%5Chat+y+%29%5E%7B%281-y%29%7D" alt="P(y|x)=\hat y^{y}(1-\hat y )^{(1-y)}"></p>
<p>对上式进行log处理（这里是因为log函数是单调函数，不会改变原函数的单调性）：</p>
<p><img src="http://www.zhihu.com/equation?tex=%5Clog+P%28y%7Cx%29%3D%5Clog%5Cleft%5B%5Chat+y%5E%7By%7D%281-%5Chat+y+%29%5E%7B%281-y%29%7D%5Cright%5D%3Dy%5Clog%5Chat+y%2B%281-y%29%5Clog%281-%5Chat+y%29" alt="\log P(y|x)=\log\left[\hat y^{y}(1-\hat y )^{(1-y)}\right]=y\log\hat y+(1-y)\log(1-\hat y)"></p>
<p>概率 <img src="http://www.zhihu.com/equation?tex=P%28y%7Cx%29" alt="P(y|x)"> 越大越好，即判断正确的概率越大越好。这里对上式加上负号，则转化成了单个样本的Loss function，我们期望其值越小越好：</p>
<p><img src="http://www.zhihu.com/equation?tex=L%28%5Chat+y%2C+y%29%3D-%28y%5Clog%5Chat+y%2B%281-y%29%5Clog%281-%5Chat+y%29%29" alt="L(\hat y, y)=-(y\log\hat y+(1-y)\log(1-\hat y))"></p>
<p><strong>m个训练样本</strong></p>
<p>假设样本之间是独立同分布的，我们总是希望训练样本判断正确的概率越大越好，则有：<img src="http://www.zhihu.com/equation?tex=%5Cmax+%5Cprod%5Climits_%7Bi%3D1%7D%5E%7Bm%7D+%7BP%28y%5E%7B%28i%29%7D%7Cx%5E%7B%28i%29%7D%29%7D" alt="\max \prod\limits_{i=1}^{m} {P(y^{(i)}|x^{(i)})}"></p>
<p>同样引入log函数，加负号，则可以得到Cost function：</p>
<p><img src="http://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7DL%28%5Chat+y%5E%7B%28i%29%7D%2C+y%5E%7B%28i%29%7D%29%3D-%5Cdfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%5By%5E%7B%28i%29%7D%5Clog%5Chat+y%5E%7B%28i%29%7D%2B%281-y%5E%7B%28i%29%7D%29%5Clog%281-%5Chat+y%5E%7B%28i%29%7D%29%5Cright%5D" alt="J(w,b)=\dfrac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum_{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/神经网络和深度学习笔记2/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-神经网络和深度学习笔记1" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/神经网络和深度学习笔记1/">神经网络介绍</a>
    </h1>
  

        
        <a href="/2018/02/05/神经网络和深度学习笔记1/" class="archive-article-date">
  	<time datetime="2018-02-05T08:01:03.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1.房价预测神经网络</p>
<p><img src="http://img.blog.csdn.net/20170925093733914?" alt="img"></p>
<p>2.数据类型一般分为两种：Structured Data和Unstructured Data。</p>
<p>简单地说，Structured Data通常指的是有实际意义的数据。例如房价预测中的size，#bedrooms，price等；例如在线广告中的User Age，Ad ID等。这些数据都具有实际的物理意义，比较容易理解。而Unstructured Data通常指的是比较抽象的数据，例如Audio，Image或者Text。以前，计算机对于Unstructured Data比较难以处理，而人类对Unstructured Data却能够处理的比较好，例如我们第一眼很容易就识别出一张图片里是否有猫，但对于计算机来说并不那么简单。现在，值得庆幸的是，由于深度学习和神经网络的发展，计算机在处理Unstructured Data方面效果越来越好，甚至在某些方面优于人类。总的来说，神经网络与深度学习无论对Structured Data还是Unstructured Data都能处理得越来越好，并逐渐创造出巨大的实用价值。</p>
        
          <a class="article-more-a" href="/2018/02/05/神经网络和深度学习笔记1/#more">more >></a>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/05/神经网络和深度学习笔记1/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-支持向量机SVM系列1总结" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/04/支持向量机SVM系列1总结/">支持向量机SVM系列【1】总结</a>
    </h1>
  

        
        <a href="/2018/02/04/支持向量机SVM系列1总结/" class="archive-article-date">
  	<time datetime="2018-02-04T09:21:06.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>一、线性分类器：</strong></p>
<p>​    <strong>首先给出一个非常非常简单的分类问题（线性可分）</strong>，我们要用一条直线，将下图中黑色的点和白色的点分开，很显然，图上的这条直线就是我们要求的直线之一（可以有无数条这样的直线）</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055565831.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055571894.png" alt="image"></a>    假如说，我们令黑色的点 = -1， 白色的点 =  +1，直线f(x) = w.x + b，这儿的x、w是向量，其实写成这种形式也是等价的f(x) = w1x1 + w2x2 … + wnxn + b, 当向量x的维度=2的时候，f(x) 表示二维空间中的一条直线， 当x的维度=3的时候，f(x) 表示3维空间中的一个平面，当x的维度=n &gt; 3的时候，表示n维空间中的n-1维超平面。这些都是比较基础的内容，如果不太清楚，可能需要复习一下微积分、线性代数的内容。</p>
<p>​    刚刚说了，我们令黑色白色两类的点分别为+1, -1，所以当有一个新的点x需要预测属于哪个分类的时候，我们用sgn(f(x))，就可以预测了，sgn表示符号函数，当f(x) &gt; 0的时候，sgn(f(x)) = +1, 当f(x) &lt; 0的时候sgn(f(x)) = –1。</p>
<p>​    但是，我们怎样才能取得一个最优的划分直线f(x)呢？下图的直线表示几条可能的f(x)</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055574369.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055574336.png" alt="image"></a></p>
<p>​    一个很直观的感受是，让这条直线到给定样本中最近的点最远，这句话读起来比较拗口，下面给出几个图，来说明一下：</p>
<p>​    第一种分法：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055573224.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055589287.png" alt="image"></a></p>
<p>​    第二种分法：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055585350.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055589777.png" alt="image"></a></p>
<p>​    这两种分法哪种更好呢？从直观上来说，就是分割的间隙越大越好，把两个类别的点分得越开越好。就像我们平时判断一个人是男还是女，就是很难出现分错的情况，这就是男、女两个类别之间的间隙非常的大导致的，让我们可以更准确的进行分类。<strong>在SVM中，称为Maximum Marginal，是SVM的一个理论基础之一。</strong>选择使得间隙最大的函数作为分割平面是由很多道理的，比如说从概率的角度上来说，就是使得置信度最小的点置信度最大（听起来很拗口），从实践的角度来说，这样的效果非常好，等等。这里就不展开讲，作为一个结论就ok了，:)</p>
<p>​    上图被红色和蓝色的线圈出来的点就是所谓的支持向量(support vector)。</p>
<p>  <a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055584204.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055599155.png" alt="image"></a>    上图就是一个对之前说的类别中的间隙的一个描述。Classifier Boundary就是f(x)，红色和蓝色的线（plus plane与minus plane）就是support vector所在的面，红色、蓝色线之间的间隙就是我们要最大化的分类间的间隙。<a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022055592153.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056007660.png" alt="image"></a></p>
<p>​    这里直接给出M的式子：（从高中的解析几何就可以很容易的得到了，也可以参考后面Moore的ppt）</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056009056.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056005675.png" alt="image"></a></p>
<p>​    另外支持向量位于wx + b = 1与wx + b = -1的直线上，我们在前面乘上一个该点所属的类别y（还记得吗?y不是+1就是-1），就可以得到支持向量的表达式为：y(wx + b) = 1，这样就可以更简单的将支持向量表示出来了。</p>
<p>​    当支持向量确定下来的时候，分割函数就确定下来了，两个问题是等价的。得到支持向量，还有一个作用是，让支持向量后方那些点就不用参与计算了。这点在后面将会更详细的讲讲。</p>
<p>​    在这个小节的最后，给出我们要优化求解的表达式：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056002611.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056009546.png" alt="image"></a></p>
<p>​    ||w||的意思是w的二范数，跟上面的M表达式的分母是一个意思，之前得到，M = 2 / ||w||，最大化这个式子等价于最小化||w||, 另外由于||w||是一个单调函数，我们可以对其加入平方，和前面的系数，熟悉的同学应该很容易就看出来了，这个式子是为了方便求导。</p>
<p>​    这个式子有还有一些限制条件，完整的写下来，应该是这样的：（<strong>原问题</strong>）</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056018433.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/20110502205601593.png" alt="image"></a></p>
<p>​    s.t的意思是subject to，也就是在后面这个限制条件下的意思，这个词在svm的论文里面非常容易见到。这个其实是一个带约束的二次规划(quadratic programming, QP)问题，是一个凸问题，凸问题就是指的不会有局部最优解，可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。s.t.后面的限制条件可以看做是一个凸多面体，我们要做的就是在这个凸多面体中找到最优解。这些问题这里不展开，因为展开的话，一本书也写不完。如果有疑问请看看wikipedia。</p>
<p><strong>二、转化为对偶问题，并优化求解:</strong></p>
<p>​    这个优化问题可以用<a href="http://en.wikipedia.org/wiki/Lagrange_multiplier" target="_blank" rel="noopener">拉格朗日乘子法</a>去解，使用了<a href="http://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions" target="_blank" rel="noopener">KKT条件</a>的理论，这里直接作出这个式子的拉格朗日目标函数：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056015020.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056017495.png" alt="image"></a></p>
<p>​    求解这个式子的过程需要<a href="http://en.wikipedia.org/wiki/Quadratic_programming#Lagrangian_duality" target="_blank" rel="noopener">拉格朗日对偶性</a>的相关知识（另外pluskid也有<a href="http://blog.pluskid.org/?p=702" target="_blank" rel="noopener">一篇文章</a>专门讲这个问题），并且有一定的公式推导，如果不感兴趣，<strong>可以直接跳到后面</strong>用<strong>蓝色公式</strong>表示的结论，该部分推导主要参考自<a href="http://blog.pluskid.org/?p=682" target="_blank" rel="noopener">plukids的文章</a>。</p>
<p>​    首先让L关于w，b最小化，分别令L关于w，b的偏导数为0，得到关于<strong>原问题</strong>的一个表达式</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056032314.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056034789.png" alt="image"></a></p>
<p>​    将两式带回L(w,b,a)得到对偶问题的表达式</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056037264.png" alt="image"></p>
<p>​    新问题加上其限制条件是（<strong>对偶问题</strong>）:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056041691.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056046118.png" alt="image"></a></p>
<p>​    这个就是我们需要最终优化的式子。至此，<strong>得到了线性可分问题的优化式子</strong>。</p>
<p>​    求解这个式子，有很多的方法，比如<a href="http://en.wikipedia.org/wiki/Sequential_minimal_optimization" target="_blank" rel="noopener">SMO</a>等等，个人认为，求解这样的一个带约束的凸优化问题与得到这个凸优化问题是比较独立的两件事情，所以在这篇文章中准备完全不涉及如何求解这个话题，如果之后有时间可以补上一篇文章来谈谈:)。</p>
<p><strong>三、线性不可分的情况（软间隔）：</strong></p>
<p>​    接下来谈谈线性不可分的情况，因为<strong>线性可分这种假设实在是太有局限性</strong>了：</p>
<p>​    下图就是一个典型的线性不可分的分类图，我们没有办法用一条直线去将其分成两个区域，每个区域只包含一种颜色的点。</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056043054.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056045213.png" alt="image"></a>     要想在这种情况下的分类器，有两种方式，<strong>一种是用曲线</strong>去将其完全分开，曲线就是一种<strong>非线性</strong>的情况，跟之后将谈到的<strong>核函数</strong>有一定的关系：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056057688.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056056576.png" alt="image"></a>     <strong>另外一种还是用直线，不过不用去保证可分性</strong>，就是包容那些分错的情况，不过我们得加入惩罚函数，使得点分错的情况越合理越好。其实在很多时候，不是在训练的时候分类函数越完美越好，因为训练函数中有些数据本来就是噪声，可能就是在人工加上分类标签的时候加错了，如果我们在训练（学习）的时候把这些错误的点学习到了，那么模型在下次碰到这些错误情况的时候就难免出错了（假如老师给你讲课的时候，某个知识点讲错了，你还信以为真了，那么在考试的时候就难免出错）。这种学习的时候学到了“噪声”的过程就是一个过拟合（over-fitting），这在机器学习中是一个大忌，我们宁愿少学一些内容，也坚决杜绝多学一些错误的知识。还是回到主题，用直线怎么去分割线性不可分的点：</p>
<p>​     我们可以为分错的点加上一点惩罚，对一个分错的点的<strong>惩罚函数</strong>就是<strong>这个点到其正确位置的距离：</strong></p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056057099.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056051526.png" alt="image"></a></p>
<p>​    在上图中，蓝色、红色的直线分别为支持向量所在的边界，绿色的线为决策函数，那些紫色的线<strong>表示分错的点到其相应的决策面的距离</strong>，这样我们可以在原函数上面加上一个惩罚函数，并且带上其限制条件为：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056054001.png" alt="image"></p>
<p>​    公式中蓝色的部分为在线性可分问题的基础上加上的惩罚函数部分，当xi在正确一边的时候，ε=0，R为全部的点的数目，C是一个由用户去指定的系数，表示对分错的点加入多少的惩罚，当C很大的时候，分错的点就会更少，但是过拟合的情况可能会比较严重，当C很小的时候，分错的点可能会很多，不过可能由此得到的模型也会不太正确，所以如何选择C是有很多学问的，不过在大部分情况下就是通过经验尝试得到的。</p>
<p>​    接下来就是同样的，求解一个拉格朗日对偶问题，得到一个原问题的对偶问题的表达式：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056067556.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/20110502205606347.png" alt="image"></a></p>
<p>​    蓝色的部分是与线性可分的对偶问题表达式的不同之处。在线性不可分情况下得到的对偶问题，不同的地方就是α的范围从[0, +∞)，变为了[0, C]，增加的惩罚ε没有为对偶问题增加什么复杂度。</p>
<p><strong>四、核函数：</strong></p>
<p>​    刚刚在谈不可分的情况下，提了一句，如果使用某些非线性的方法，可以得到将两个分类完美划分的曲线，比如接下来将要说的核函数。</p>
<p><strong>    </strong>我们可以<strong>让空间从原本的线性空间变成一个更高维的空间</strong>，<strong>在这个高维的线性空间下，再用一个超平面进行划分</strong>。这儿举个例子，来理解一下如何利用空间的维度变得更高来帮助我们分类的（例子以及图片来自<a href="http://blog.pluskid.org/?p=685" target="_blank" rel="noopener">pluskid的kernel函数部分</a>）：</p>
<p>​    下图是一个典型的线性不可分的情况</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056068362.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056079965.png" alt="image"></a></p>
<p>​    但是当我们把这两个类似于椭圆形的点映射到一个高维空间后，映射函数为：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056071361.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056078296.png" alt="image"></a>    用这个函数可以将上图的平面中的点映射到一个三维空间（z1,z2,z3)，并且对映射后的坐标加以旋转之后就可以得到一个线性可分的点集了。</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056107476.gif" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056122751.gif" alt="rotate"></a></p>
<p>​    用另外一个哲学例子来说：世界上本来没有两个完全一样的物体，对于所有的两个物体，我们可以通过增加维度来让他们最终有所区别，比如说两本书，从(颜色，内容)两个维度来说，可能是一样的，我们可以加上 <strong>作者</strong> 这个维度，是在不行我们还可以加入<strong>页码</strong>，可以加入 <strong>拥有者</strong>，可以加入 <strong>购买地点</strong>，可以加入 <strong>笔记内容</strong>等等。<strong>当维度增加到无限维的时候，一定可以让任意的两个物体可分了</strong>。</p>
<p>​    回忆刚刚得到的对偶问题表达式：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056126306.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056134322.png" alt="image"></a></p>
<p>​    我们可以将红色这个部分进行改造，令：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056135717.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056132652.png" alt="image"></a>     这个式子所做的事情就是将线性的空间映射到高维的空间,k(x, xj)有很多种，下面是比较典型的两种：</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056135128.png" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201105/201105022056149239.png" alt="image"></a>    上面这个核称为多项式核，下面这个核称为高斯核，高斯核甚至是将原始空间映射为无穷维空间，另外核函数有一些比较好的性质，比如说不会比线性条件下增加多少额外的计算量，等等，这里也不再深入。一般对于一个问题，不同的核函数可能会带来不同的结果，一般是需要尝试来得到的。</p>
<p><strong>五、一些其他的问题：</strong></p>
<p>​     1）如何进行多分类问题：</p>
<p>​     上面所谈到的分类都是2分类的情况，当N分类的情况下，主要有两种方式，一种是1 vs (N – 1)一种是1 vs 1，前一种方法我们需要训练N个分类器，第i个分类器是看看是属于分类i还是属于分类i的补集（出去i的N-1个分类）。</p>
<p>​     后一种方式我们需要训练N * (N – 1) / 2个分类器，分类器(i,j)能够判断某个点是属于i还是属于j。</p>
<p>​     这种处理方式不仅在SVM中会用到，在很多其他的分类中也是被广泛用到，从林教授（libsvm的作者）的结论来看，1 vs 1的方式要优于1 vs (N – 1)。</p>
<p>​     2）SVM会overfitting吗？</p>
<p>​     SVM避免overfitting，一种是调整之前说的惩罚函数中的C，另一种其实从式子上来看，min ||w||^2这个看起来是不是很眼熟？在最小二乘法回归的时候，我们看到过这个式子，这个式子可以让函数更平滑，所以SVM是一种不太容易over-fitting的方法。</p>
<p>转载：<a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html" target="_blank" rel="noopener">http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">SVM</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习//" class="article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/04/支持向量机SVM系列1总结/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-拉格朗日乘子和KKT" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/04/拉格朗日乘子和KKT/">拉格朗日和KKT</a>
    </h1>
  

        
        <a href="/2018/02/04/拉格朗日乘子和KKT/" class="archive-article-date">
  	<time datetime="2018-02-04T09:20:28.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="（一）关于拉格朗日乘子法"><a href="#（一）关于拉格朗日乘子法" class="headerlink" title="（一）关于拉格朗日乘子法"></a>（一）关于拉格朗日乘子法</h3><p>首先来了解拉格朗日乘子法，那么为什么需要拉格朗日乘子法？记住，有拉格朗日乘子法的地方，必然是一个组合优化问题。那么带约束的优化问题很好说，就比如说下面这个： </p>
<p>minf=2x21+3x22+7x23s.t.2x1+x2=12x2+3x3=2</p>
<p>这是一个带等式约束的优化问题，有目标值，有约束条件。那么想想假设没有约束条件这个问题是怎么求解的呢？是不是直接f对各个x求导等于0,，解x就可以了，可以看到没有约束的话，求导为0，那么各个x均为0吧，这样f=0了，最小。但是x都为0不满足约束条件呀，那么问题就来了。这里在说一点的是，为什么上面说求导为0就可以呢？理论上多数问题是可以的，但是有的问题不可以。如果求导为0一定可以的话，那么f一定是个凸优化问题，什么是凸的呢？像下面这个左图：<br><img src="http://img.blog.csdn.net/20150817184156719" alt="这里写图片描述"></p>
<p>凸的就是开口朝一个方向（向上或向下）。更准确的数学关系就是： </p>
<p>f(x1)+f(x2)2&gt;f(x1+x22)或者f(x1)+f(x2)2&lt;f(x1+x22)</p>
<p>注意的是这个条件是</p>
<p>对函数的任意x取值</p>
<p>。如果满足第一个就是开口向上的凸，第二个是开口向下的凸。可以看到对于凸问题，你去求导的话，是不是只有一个极点，那么他就是最优点，很合理。类似的看看上图右边这个图，很明显这个条件对任意的x取值不满足，有时满足第一个关系，有时满足第二个关系，对应上面的两处取法就是，所以这种问题就不行，再看看你去对它求导，会得到好几个极点。然而从图上可以看到，只有其中一个极点是最优解，其他的是局部最优解，那么当真实问题的时候你选择那个？说了半天要说啥呢，就是拉格朗日法是一定适合于凸问题的，不一定适合于其他问题，还好我们最终的问题是凸问题。</p>
<p>回头再来看看有约束的问题，既然有了约束不能直接求导，那么如果把约束去掉不就可以了吗？怎么去掉呢？这才需要拉格朗日方法。既然是等式约束，那么我们把这个约束乘一个系数加到目标函数中去，这样就相当于既考虑了原目标函数，也考虑了约束条件，比如上面那个函数，加进去就变为： </p>
<p>minf=2x21+3x22+7x23+α1(2x1+x2−1)+α2(2x2+3x3−2)</p>
<p>这里可以看到与</p>
<p>α1,α2</p>
<p>相乘的部分都为0，所以</p>
<p>α1,α2</p>
<p>的取值为全体实数。现在这个优化目标函数就没有约束条件了吧，既然如此，求法就简单了，分别对x求导等于0，如下： </p>
<p>∂f∂x1=4x1+2α1=0⇒x1=−0.5α1∂f∂x2=6x2+α1+2α2=0⇒x2=−α1+2α26∂f∂x3=14x3+3α2=0⇒x3=−3α214</p>
<p>把它在带到约束条件中去，可以看到，2个变量两个等式，可以求解，最终可以得到α1=−0.39,α2=−1.63,这样再带回去求x就可以了。那么一个带等式约束的优化问题就通过拉格朗日乘子法完美的解决了。那么更高一层的，带有不等式的约束问题怎么办？那么就需要用更一般化的拉格朗日乘子法即KKT条件来解决这种问题了。</p>
<h3 id="（二）关于KKT条件"><a href="#（二）关于KKT条件" class="headerlink" title="（二）关于KKT条件"></a>（二）关于KKT条件</h3><p>继续讨论关于带等式以及不等式的约束条件的凸函数优化。任何原始问题约束条件无非最多3种，等式约束，大于号约束，小于号约束，而这三种最终通过将约束方程化简化为两类：约束方程等于0和约束方程小于0。再举个简单的方程为例，假设原始约束条件为下列所示： </p>
<p>minf=x21−2x1+1+x22+4x2+4s.t.x1+10x2&gt;1010x1−10x2&lt;10</p>
<p>那么把约束条件变个样子： </p>
<p>s.t.10−x1−10x2&lt;010x1−x2−10&lt;0</p>
<p>为什么都变成等号与小于号，方便后面的，反正式子的关系没有发生任何变化就行了。</p>
<p>现在将约束拿到目标函数中去就变成： </p>
<p>L(x,α)=f(x)+α1g1(x)+α2g2(x)=x21−2x1+1+x22+4x2+4+α1(10−x1−10x2)+α2(10x1−x2−10)</p>
<p>那么KKT条件的定理是什么呢？就是如果一个优化问题在转变完后变成</p>
<p>L(x,α,β)=f(x)+∑αigi(x)+∑βihi(x)</p>
<p>其中g是不等式约束，h是等式约束（像上面那个只有不等式约束，也可能有等式约束）。那么KKT条件就是函数的最优值必定满足下面条件：</p>
<p>(1) L对各个x求导为零；<br>(2) h(x)=0;<br><strong>(3) ∑αigi(x)=0，αi≥0</strong></p>
<p>这三个式子前两个好理解，重点是第三个式子不好理解，因为我们知道在约束条件变完后，所有的g(x)&lt;=0，且αi≥0，然后求和还要为0，无非就是告诉你，要么某个不等式gi(x)=0,要么其对应的αi=0。那么为什么KKT的条件是这样的呢？</p>
<p>假设有一个目标函数，以及它的约束条件，形象的画出来就如下：<br><img src="http://img.blog.csdn.net/20150817184659520" alt="这里写图片描述"><br>假设就这么几个吧，最终约束是把自变量约束在一定范围，而函数是在这个范围内寻找最优解。函数开始也不知道该取哪一个值是吧，那就随便取一个，假设某一次取得自变量集合为x1<em>，发现一看，不满足约束，然后再换呀换，换到了x2</em>,发现可以了，但是这个时候函数值不是最优的，并且x2<em>使得g1(x)与g2(x)等于0了，而g3(x)还是小于0。这个时候，我们发现在x2的基础上再寻找一组更优解要靠谁呢？当然是要靠约束条件g1(x)与g2(x)，因为他们等于0了，很极限呀，一不小心，走错了就不满足它们两了，这个时候我们会选择g1(x)与g2(x)的梯度方向往下走，这样才能最大程度的拜托g1(x)与g2(x)=0的命运，使得他们满足小于0的约束条件对不对。至于这个时候需不需要管g3(x)呢？正常来说管不管都可以，如果管了，也取g3在x2</em>处的梯度的话，因为g3已经满足了小于0的条件，这个时候在取在x2<em>处的梯度，你能保证它是往好的变了还是往差的变了？答案是都有可能。运气好，往好的变了，可以更快得到结果，运气不好，往差的变了，反而适得其反。那么如果不管呢？因为g1(x)与g2(x)已经在边缘了，所以取它的梯度是一定会让目标函数变好的。综合来看，这个时候我们就不选g3。那么再往下走，假设到了自变量优化到了x3</em>，这个时候发现g2(x)与g3(x)等于0，也就是走到边了，而g1(x)小于0，可变化的空间绰绰有余，那么这个时候举要取g2(x)与g3(x)的梯度方向作为变化的方向，而不用管g1(x)。那么一直这样走呀走，最终找到最优解。可以看到的是，上述如果g1(x)、g2(x)=0的话，我们是需要优化它的，又因为他们本身的条件是小于0的，所以最终的公式推导上表明，是要乘以一个正系数α作为他们梯度增长的倍数，而那些不需要管的g(x)为了统一表示，这个时候可以将这个系数设置为0，那么这一项在这一次的优化中就没有了。那么把这两种综合起来就可以表示为<br>∑αigi(x)=0，αi≥0。<br>也即是某次的g(x)在为最优解起作用，那么它的系数值(可以)不为0。如果某次g(x)没有为下一次的最优解x的获得起到作用，那么它的系数就必须为0，这就是这个公式的含义。</p>
<p>比如上面例子的目标值与约束： </p>
<p>minf=x21−2x1+1+x22+4x2+4s.t.10−x1−10x2&lt;010x1−x2−10&lt;0</p>
<p>将约束提到函数中有： </p>
<p>L(x,α)=x21−2x1+1+x22+4x2+4+α1(10−x1−10x2)+α2(10x1−x2−10)</p>
<p>此时分别对x1、x2求导数： </p>
<p>∂L∂x1=2x1−2−α1+10α2=0⇒x1=0.5(α1−10α2+2)∂L∂x2=2x2+4−10α1−α2=0⇒x2=0.5(10α1+α2−4)</p>
<p>而我们还有一个条件就是</p>
<p>α∗g(x)=0</p>
<p>,那么也就是： </p>
<p>α1∗g1(x)=α1∗(10−x1−10x2)=0α2∗g2(x)=α2∗(10x1−x2−10)=0</p>
<p>这样我们就去讨论下，要么g=0，要么α=0，这里两个g两个α，这样我们就需要讨论四种情况，可能你会说，这是约束条件少的情况，那么如果有10个约束条件，这样就有10个g和10个α，你去给我讨论？多少种组合，不知道，但是换个思路，我们非得去10个一起去讨论？机智的学者想到一种方法，考虑到∑αigi(x)=0这个条件，那么我两个两个讨论不就可以了，比如现在我就讨论α7，α8，让其他的α不变，为什么选或者至少选两个讨论呢，因为这个式子求和为0，改变一个显然是不行的，那就改变两个，你增我就减，这样和可以为0。再问为什么不讨论3个呢？也可以，这不是麻烦嘛，一个俗语怎么说来着，三个和尚没水喝，假设你改变了一个，另外两个你说谁去减或者加使得和为0，还是两个都变化一点呢？不好说吧，自然界都是成双成对的才和谐，没有成三成四的（有的话也少）。这里顺便提一下后面会介绍到的内容，就是实现SVM算法的SMO方法，在哪里，会有很多α，那么人们怎么解决的呢，就是随便选择两个α去变化，看看结果好的话，就接受，不好的话就舍弃在选择两个α，如此反复，后面介绍。说回来，这里有四种情况，正好两个α，也不用挑不用减的，一次完事。那么我们分着讨论吧， </p>
<p>（1）α1=α2=0，那么看上面的关系可以得到x1=1,x2=−1,再把两个x带到不等式约束，发现第一个就是需要满足（10-1+20=29<0)显然不行，29>0的。舍弃</0)显然不行，29></p>
<p>（2）g1(x)=g2(x)=0，带进去解得，x1=110/101;x2=90/101,再带回去求解α1，α2，发现α1=58/101，α2=4/101，它们满足大于0的条件，那么显然这组解是可以的。</p>
<p>（3）其他两种情况再去讨论发现是不行的。</p>
<p>可以看到像这种简单的讨论完以后就可以得到解了。<br>x1=110/101=1.08;x2=90/101=0.89,那么它得到结果对不对呢？这里因为函数简单，可以在matlab下画出来，同时约束条件也可以画出来，那么原问题以及它的约束面画出来就如下所示：<br><img src="http://img.blog.csdn.net/20150817185059261" alt="这里写图片描述"><br>这是截取下来的符合约束要求的目标面<br><img src="http://img.blog.csdn.net/20150817185127384" alt="这里写图片描述"><br>可以看到最优解确实就是上面我们求的那个解。既然简单的问题可以这样解，那么复杂一点的只需要简单化，照样可以解，至此KKT条件解这类约束性问题就是这样，它对后续的SVM求解最优解至关重要。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">SVM</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习//" class="article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/04/拉格朗日乘子和KKT/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-逻辑回归总结" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/04/逻辑回归总结/">逻辑回归总结</a>
    </h1>
  

        
        <a href="/2018/02/04/逻辑回归总结/" class="archive-article-date">
  	<time datetime="2018-02-04T09:19:44.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在这个算法里，我们的假设函数<img src="https://www.zhihu.com/equation?tex=h%28x%29" alt="h(x)">长这样：<img src="https://www.zhihu.com/equation?tex=h%28x%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Ctheta%5ET%2AX%7D+%7D+" alt="h(x)=\frac{1}{1+e^{-\theta^T*X} } "></p>
<p>简化一下，把<img src="https://www.zhihu.com/equation?tex=%5Ctheta%5ET%2AX" alt="\theta^T*X">叫做Z，那么原函数就变成了<img src="https://www.zhihu.com/equation?tex=g%28z%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D+%7D+" alt="g(z)=\frac{1}{1+e^{-z} } "></p>
<p>图示如下：</p>
<p><img src="https://pic4.zhimg.com/faa829b805c529c5dd039896034ac7dd_b.jpg" alt="img"></p>
<p><img src="https://pic1.zhimg.com/a23df30a3d3d14306fd07d45ee490542_b.jpg" alt="img"></p>
<p>嗯。反正差不多，所以高数的知识可以直接拿过来用了。</p>
<p>逻辑回归算法，计算目的是为了分类。按照图中所示，当<img src="https://www.zhihu.com/equation?tex=z%3E0" alt="z&gt;0">的时候，<img src="https://www.zhihu.com/equation?tex=g%28z%29" alt="g(z)">大于0.5，那么假如你要分类，1为在某类，0为不在某类，那<img src="https://www.zhihu.com/equation?tex=g%28z%29" alt="g(z)">四舍五入就是1个1……。同理，z&lt;0时，g（z）&lt;0.5，四舍五入到0……（当然实际不是这么做的，实际做法是用数学方法使z的绝对值超过一个界限，使得<img src="https://www.zhihu.com/equation?tex=g%28z%29" alt="g(z)">和1或者0很近。）</p>
<p>我们可以把g(z)=0.5,也就是z=0的时候，称为<strong>决策边界</strong>。假设y为结果，y的值是1或者0。</p>
<p>那么，z=0，也就是<img src="https://www.zhihu.com/equation?tex=%5Ctheta%5ET%2AX" alt="\theta^T*X">=0的时候为边界。<img src="https://www.zhihu.com/equation?tex=%5Ctheta%5ET%2AX%5Cgeq+0" alt="\theta^T*X\geq 0">时y=1。<img src="https://www.zhihu.com/equation?tex=%5Ctheta%5ET%2AX%3C+0" alt="\theta^T*X&lt; 0">时y=0。分类就靠这个……</p>
<p>然后继续，机器学习嘛，根据前两周的经验，肯定有那个J，代价函数。逻辑回归算法的代价函数如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%3D1%2Fm%2A%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28%7Bh%28x_i%29-y_i%7D+%29%5E2" alt="J=1/m*\sum_{i=1}^{m}({h(x_i)-y_i} )^2">（m是y总数，嫌麻烦的话，和第二周一样，如果你把那个加和符号去掉，那么这里x和y就变成向量了也就是：<img src="https://www.zhihu.com/equation?tex=J%3D1%2Fm%2A%28%7Bh%28x%29-y%7D+%29.%5E2" alt="J=1/m*({h(x)-y} ).^2">。）</p>
<p>然后因为y只有0和1两个取值，这里就可以分两种情况讨论，让y从函数中去掉：</p>
<p>y=0：<img src="https://www.zhihu.com/equation?tex=J%3D1%2Fm%2A%5Csum_%7B1%7D%5E%7Bm%7D%28%7Bh%28x%29-0%7D+%29%5E2" alt="J=1/m*\sum_{1}^{m}({h(x)-0} )^2"></p>
<p>y=1:<img src="https://www.zhihu.com/equation?tex=J%3D1%2Fm%2A%5Csum_%7B1%7D%5E%7Bm%7D%28%7Bh%28x%29-1%7D+%29%5E2" alt="J=1/m*\sum_{1}^{m}({h(x)-1} )^2"></p>
<p>然而我们发现，这样拿出来的函数，因为y一会儿是1，一会儿是0，得到的图像如下（左边的）然而左边的凹凸不平（非凸），不方便梯度下降，我们想要的是右边那种滑溜溜（凸）的图像。：</p>
<p><img src="https://pic2.zhimg.com/7ce98c3ddfb66f85017fc4af7a423176_b.jpg" alt="img"></p>
<p>原函数J变成了<img src="https://www.zhihu.com/equation?tex=J%3D1%2Fm%2A%5Csum_%7B1%7D%5E%7Bm%7D%28cost%28h%28x%29%2Cy%29" alt="J=1/m*\sum_{1}^{m}(cost(h(x),y)"></p>
<p>反正我们要的是<img src="https://www.zhihu.com/equation?tex=cost%3D%28h%28x%29%2Cy%29" alt="cost=(h(x),y)">符合决策边界的条件就可以了，反正都把结果四舍五入成1或者0了，也没必要非得是某个函数对吧？</p>
<p>所以它是什么函数无所谓。只要（它的函数处理了x以后，得到的y）符合决策边界的条件即可。而现在我们希望得到一个滑溜溜的凸函数。那么我们就假设（注意，这是假设出来的，符合条件的函数之一，没说非得这样。然而这是已有的函数中最好的。）：</p>
<p>y=1的时候，<img src="https://www.zhihu.com/equation?tex=cost%3D%28h%28x%29%2Cy%29%3D-log%28h%28x%29%29" alt="cost=(h(x),y)=-log(h(x))"></p>
<p>y=0的时候，<img src="https://www.zhihu.com/equation?tex=cost%3D%28h%28x%29%2Cy%29%3D-log%281-h%28x%29%29" alt="cost=(h(x),y)=-log(1-h(x))"></p>
<p>它们的图像如下：</p>
<p><img src="https://pic1.zhimg.com/49c392586f8b1280d37be6e0cc62e00e_b.jpg" alt="img"></p>
<p>符合条件。那么这时候还有一个问题，大家都很懒对吧，懒得分情况讨论，那么如何做呢？</p>
<p>你看，由于y只有1和0两个值，所以我们就直接把两种情况的cost函数相加，然后分别乘以y和y-1即可：</p>
<p>看，是不是很方便呢？</p>
<p>于是原来的那个代价函数J就变成了：</p>
<p>然后照旧，我们目的是拿x和y训练样本得到<img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta">嘛！所以对这玩意求导，然后取个α，然后不断重复梯度下降……以得到<img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta">，就是下面这个玩意：</p>
<p>（repeat：）<img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%3D%5Ctheta_j-%5Calpha+%2A%5Cfrac%7Bd%7D%7Bd%5Ctheta_j%7DJ%28%5Ctheta%29+" alt="\theta_j=\theta_j-\alpha *\frac{d}{d\theta_j}J(\theta) "></p>
<p>这坨玩意里，我们需要计算<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bd%5Ctheta_j%7DJ%28%5Ctheta%29+" alt="\frac{d}{d\theta_j}J(\theta) ">，直接照搬之前笔记里的，<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bd%5Ctheta_j%7DJ%28%5Ctheta%29+%3D1%2Fm%2A%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%28h%28x_i%29-y_i%29%7D+%2Ax_%7Bi%2Cj%7D" alt="\frac{d}{d\theta_j}J(\theta) =1/m*\sum_{i=1}^{m}{(h(x_i)-y_i)} *x_{i,j}">即可。只不过这里的<img src="https://www.zhihu.com/equation?tex=h%28x%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Ctheta%5ET%2AX%7D+%7D+" alt="h(x)=\frac{1}{1+e^{-\theta^T*X} } "></p>
<p>于是我们最终得到的</p>
<p>（repeat：）<img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%3D%5Ctheta_j-%5Calpha+%2Fm%2A%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%28h%28x_i%29-y_i%29%7D+%2Ax_%7Bi%2Cj%7D" alt="\theta_j=\theta_j-\alpha /m*\sum_{i=1}^{m}{(h(x_i)-y_i)} *x_{i,j}"></p>
<p>逻辑回归函数就是这样了。</p>
<p>然后是拟合问题，下面是3种情况：</p>
<p><img src="https://pic1.zhimg.com/c278dcb3c42ff6b9c7d914b85030d77d_b.jpg" alt="img"></p>
<p>第一种是欠拟合，通常是因为特征量选少了。第二种是我们想要的，第三个是过拟合，通常是因为特征量选多了。</p>
<p>欠拟合的解决方法是增加特征量。</p>
<p>过拟合的解决方法是减少特征量或者正则化。</p>
<p>比如我们的逻辑回归函数，不选个自定义的函数，就用我们那个类似泰勒展开式的函数来做的画，这货长得凹凸不平的</p>
<p><img src="https://pic3.zhimg.com/e77581efac0120995f21720c424c0741_b.jpg" alt="img"></p>
<p><img src="https://pic1.zhimg.com/b1d00724220a2791374343761ccf4b3f_b.jpg" alt="img"></p>
<p>我们想要的，是一根滑溜溜的凸函数，但是我们又不能确定哪些特征量该去掉，所以我们就选择正则化的方式解决过拟合。</p>
<p>正则化的方法，就是给代价函数后面加个“惩罚项”……来降低它对数据的拟合能力。</p>
<p>于是我们的<img src="https://www.zhihu.com/equation?tex=J%3D1%2F2m%2A%5Csum_%7B1%7D%5E%7Bm%7D%28-y%2Alog%28h%28x%29%29%2B%28y-1%29log%281-h%28x%29%29%29" alt="J=1/2m*\sum_{1}^{m}(-y*log(h(x))+(y-1)log(1-h(x)))"></p>
<p>就变成了：<img src="https://www.zhihu.com/equation?tex=J%3D1%2F2m%2A%28%5Csum_%7B1%7D%5E%7Bm%7D%28-y%2Alog%28h%28x%29%29%2B%28y-1%29log%281-h%28x%29%29%29%2B%5Clambda+%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%7B%5Ctheta_j%5E2%7D+%29" alt="J=1/2m*(\sum_{1}^{m}(-y*log(h(x))+(y-1)log(1-h(x)))+\lambda \sum_{j=1}^{n}{\theta_j^2} )">（这里n表示特征量的总数，意思就是让所有的n个正义的<img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta">为了解决过拟合问题，大喊一声“合体！”然后一起来惩罚那个过度拟合了的函数……<img src="https://www.zhihu.com/equation?tex=%5Clambda+" alt="\lambda ">是正规化参数，决定了你惩罚得有多狠。你要惩罚狠点，你就把<img src="https://www.zhihu.com/equation?tex=%5Clambda+" alt="\lambda ">提高一点，<img src="https://www.zhihu.com/equation?tex=%5Clambda+" alt="\lambda ">过高会变得欠拟合，<img src="https://www.zhihu.com/equation?tex=%5Clambda+" alt="\lambda ">过小无法解决过拟合。）</p>
<p>那么我们的<img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%3D%5Ctheta_j-%5Calpha+%2Fm%2A%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%28h%28x_i%29-y_i%29%7D+%2Ax_%7Bi%2Cj%7D" alt="\theta_j=\theta_j-\alpha /m*\sum_{i=1}^{m}{(h(x_i)-y_i)} *x_{i,j}">就顺利变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%3D%5Ctheta_j%281-%5Calpha+%2A%5Clambda+%2Fm%29-%5Calpha+%2Fm%2A%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28%7B%28h%28x_i%29-y_i%29%7D+%2Ax_%7Bi%2Cj%7D%29" alt="\theta_j=\theta_j(1-\alpha *\lambda /m)-\alpha /m*\sum_{i=1}^{m}({(h(x_i)-y_i)} *x_{i,j})">    ~→</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%3D%5Ctheta_j-%5Calpha+%2Fm%2A%28%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%28h%28x_i%29-y_i%29%7D+%2Ax_%7Bi%2Cj%7D%2B%5Clambda+%2Fm%2A%5Ctheta_j%29" alt="\theta_j=\theta_j-\alpha /m*(\sum_{i=1}^{m}{(h(x_i)-y_i)} *x_{i,j}+\lambda /m*\theta_j)">。</p>
<p>注意，当<img src="https://www.zhihu.com/equation?tex=%5Ctheta_0" alt="\theta_0">的时候，由于<img src="https://www.zhihu.com/equation?tex=x_0" alt="x_0">=1，所以这一项不会欠拟合也不会过拟合，所以不惩罚它。</p>
<p>然后，如果你用的不是线性回归，而是正规方程的话，同理，给</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">varsigma =ones(n+1,n+1); #没有ones方法的自己写个循环给列表赋值，非常简单。</span><br><span class="line">varsigma [0,0]=0 #python，c，php等编程的话，等这里是0，0</span><br><span class="line">varsigma [1,1]=0 #matlab等这里是1，1，因为一个从0开始计数，一个从1开始计数。真是……就不能统一一下么，老因为这个引起一群嘴强王者的唇战。</span><br><span class="line">写出来差不多就是这样一个矩阵:</span><br><span class="line">[</span><br><span class="line">0,0,0,0,0,0,0,0,...,0,0</span><br><span class="line">0,1,0,0,0,0,0,0,...,0,0</span><br><span class="line">0,0,1,0,0,0,0,0,...,0,0</span><br><span class="line">0,0,0,1,0,0,0,0,...,0,0</span><br><span class="line">0,0,0,0,1,0,0,0,...,0,0</span><br><span class="line">0,0,0,0,0,1,0,0,...,0,0</span><br><span class="line">0,0,0,0,0,0,1,0,...,0,0</span><br><span class="line">0,0,0,0,0,0,0,1,...,0,0</span><br><span class="line">.                     .</span><br><span class="line">.                     .</span><br><span class="line">.                     .</span><br><span class="line">0,0,0,0,0,0,0,0,...,0,1</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>得到的正规化后的公式为<img src="https://www.zhihu.com/equation?tex=%5Ctheta%3D%28X%5ET%2AX%2B%5Clambda+%2A%5Cvarsigma+%29%5E%7B-1%7D+%2AX%5ET%2Ay" alt="\theta=(X^T*X+\lambda *\varsigma )^{-1} *X^T*y"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">逻辑回归</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习//" class="article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/04/逻辑回归总结/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-线性回归总结" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/04/线性回归总结/">线性回归总结【1】</a>
    </h1>
  

        
        <a href="/2018/02/04/线性回归总结/" class="archive-article-date">
  	<time datetime="2018-02-04T09:13:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-02-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-单变量线性回归-Linear-Regression-with-One-Variable"><a href="#1-单变量线性回归-Linear-Regression-with-One-Variable" class="headerlink" title="1. 单变量线性回归(Linear Regression with One Variable)"></a>1. 单变量线性回归(Linear Regression with One Variable)</h3><h4 id="1-1-模型表示"><a href="#1-1-模型表示" class="headerlink" title="1.1 模型表示"></a>1.1 模型表示</h4><p><img src="http://upload-images.jianshu.io/upload_images/3012260-a6d5768c43fb85c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/172" alt="img"></p>
<p>单变量线性回归</p>
<p>像上述公式，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
<p>例子如下：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-63e145fce22cc011.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>回归函数图示</p>
<p>单变量线性方程，就是我们初中就学的一元一次函数。<br>当然啦，除了这个模型之外，我们还有很多其他的线性模型，比如指数模型、对数模型等等，除了线性模型之外，还有非线性模型，有这么多的模型，其目的就是在于更好的拟合训练集的数据，以使得预测率更高。</p>
<p>以下是对模型的具体定义：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-f3f61877293c3449.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>回归图示</p>
<h3 id="2-代价函数-Cost-Function"><a href="#2-代价函数-Cost-Function" class="headerlink" title="2. 代价函数(Cost Function)"></a>2. 代价函数(Cost Function)</h3><blockquote>
<p>代价函数就是为了就是找到目的函数的最优解。</p>
</blockquote>
<p>因为在一个训练集中，有无数个模型（一元一次函数），我们需要找到最拟合这个训练集的一个函数，所以就引入了代价函数，用来找到那个最好的模型。</p>
<h4 id="2-1公式表示"><a href="#2-1公式表示" class="headerlink" title="2.1公式表示"></a>2.1公式表示</h4><p><img src="http://upload-images.jianshu.io/upload_images/3012260-191197cdb45a545a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/315" alt="img"></p>
<p>代价函数</p>
<p>上述是平方误差代价函数，这也是常用到的代价函数，它通过目的函数跟各个实际值的误差平方建立新的函数。为了使这个值不受个别极端数据影响而产生巨大波动，采用类似方差再取二分之一的方式来减小个别数据的影响。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-54e42067c1836645.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>平方误差代价函数图示</p>
<h4 id="2-2-代价函数的直观理解①"><a href="#2-2-代价函数的直观理解①" class="headerlink" title="2.2 代价函数的直观理解①"></a>2.2 代价函数的直观理解①</h4><p>最优解即为代价函数的最小值，根据以上公式多次计算可得到代价函数的图像：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-fb49ceb8fc72d23a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/673" alt="img"></p>
<p>代价函数图示</p>
<p>可以看到该代价函数的确有最小值，这里恰好是横坐标为1的时候。</p>
<h4 id="2-3-代价函数的直观理解②"><a href="#2-3-代价函数的直观理解②" class="headerlink" title="2.3 代价函数的直观理解②"></a>2.3 代价函数的直观理解②</h4><p>如果有更多参数，就会更为复杂，两个参数的时候就已经是三维图像了：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-1571cf5726674c91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>代价函数图示2</p>
<h3 id="3-梯度下降算法-Gradient-Descent"><a href="#3-梯度下降算法-Gradient-Descent" class="headerlink" title="3. 梯度下降算法(Gradient Descent)"></a>3. 梯度下降算法(Gradient Descent)</h3><blockquote>
<p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数J(θ0,θ1) 的最小值。</p>
</blockquote>
<p>个人理解，代价函数是分析模型与实际训练集之间的误差，而梯度下降算法的作用，就是找出那个误差最小的代价函数。</p>
<h4 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h4><p><img src="http://upload-images.jianshu.io/upload_images/3012260-4483dae7b0bcfdb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>算法思想</p>
<ul>
<li>从参数的某一个（组）值开始，比如从θ0=0和θ1=0开始</li>
<li>保持该（组）值持续减小，如果是一组值就要保证他们<strong>同步更新</strong>，直到找到我们希望找到的最小值</li>
</ul>
<p>我们要找到一条最快下山的路径，我们走的每一步大小就是α 。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-be695f829cf7ec8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>梯度下降图示1</p>
<p>如果在不同的起点，最后到达的最低点也会不一样。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-ac8e71c4939bc4b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>梯度下降图示2</p>
<h4 id="3-1批量梯度下降-batch-gradient-descent"><a href="#3-1批量梯度下降-batch-gradient-descent" class="headerlink" title="3.1批量梯度下降(batch gradient descent)"></a>3.1批量梯度下降(batch gradient descent)</h4><p><img src="http://upload-images.jianshu.io/upload_images/3012260-fb2e4da37f784b64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/528" alt="img"></p>
<p>批量梯度下降</p>
<ul>
<li>α：学习速率，决定我们让代价函数下降程度最大的方向迈出的步子有多大</li>
</ul>
<h5 id="3-1-1-同步更新-Simultaneous-update"><a href="#3-1-1-同步更新-Simultaneous-update" class="headerlink" title="3.1.1 同步更新(Simultaneous update)"></a>3.1.1 同步更新(Simultaneous update)</h5><p>在梯度下降算法中，我们需要更新θ0,θ1，实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要<strong>同时</strong>更新。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-b9ac6f6c8e4ae4f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/462" alt="img"></p>
<p>同步更新公式</p>
<h5 id="3-1-2-梯度下降算法理解"><a href="#3-1-2-梯度下降算法理解" class="headerlink" title="3.1.2 梯度下降算法理解"></a>3.1.2 梯度下降算法理解</h5><p>如果 α 太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果 α 太大，它会导致无法收敛，甚至发散。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-04be937369aee434.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/657" alt="img"></p>
<p>对α的理解</p>
<h5 id="解决方法——乘偏导数"><a href="#解决方法——乘偏导数" class="headerlink" title="解决方法——乘偏导数"></a>解决方法——乘偏导数</h5><p><img src="http://upload-images.jianshu.io/upload_images/3012260-d709146129e3cba8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>批量梯度下降直观图</p>
<p>首先初始化我的梯度下降算法，在那个品红色的点初始化，如果<br>我更新一步梯度下降，随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所 以，我再进行一步梯度下降时，我的导数项是更小的，θ1更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。</p>
<h5 id="3-1-3-线性回归的批量梯度下降"><a href="#3-1-3-线性回归的批量梯度下降" class="headerlink" title="3.1.3 线性回归的批量梯度下降"></a>3.1.3 线性回归的批量梯度下降</h5><p>偏导数求解推导过程</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-d2614d40be9bd3bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/342" alt="img"></p>
<p>偏导数求解推导过程</p>
<h5 id="批量梯度下降方程"><a href="#批量梯度下降方程" class="headerlink" title="批量梯度下降方程"></a>批量梯度下降方程</h5><p>通过上面几条公式的整合，最终得出以下公式</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-14960fdce63e7804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/528" alt="img"></p>
<p>线性回归方程</p>
<h4 id="4-线性代数基础"><a href="#4-线性代数基础" class="headerlink" title="4. 线性代数基础"></a>4. 线性代数基础</h4><p>个人现在认为，线性代数的作用主要是为了方便操作训练集。</p>
<h5 id="4-1-矩阵的定义"><a href="#4-1-矩阵的定义" class="headerlink" title="4.1 矩阵的定义"></a>4.1 矩阵的定义</h5><p>横为行，竖为列，表示方法一般是R^(m*n)</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-10e03c4ad5ff9764.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>矩阵的定义</p>
<p>寻找某个矩阵元素</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-7869e41523b65eb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>某个矩阵元素</p>
<h5 id="4-2-矩阵加法-Matrix-Addition"><a href="#4-2-矩阵加法-Matrix-Addition" class="headerlink" title="4.2 矩阵加法(Matrix Addition)"></a>4.2 矩阵加法(Matrix Addition)</h5><p>同一个位置的矩阵元素相加，得到新的矩阵</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-5be88f7936d62d83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/563" alt="img"></p>
<p>矩阵加法</p>
<h5 id="4-3-矩阵乘法-Scalar-Multiplication"><a href="#4-3-矩阵乘法-Scalar-Multiplication" class="headerlink" title="4.3 矩阵乘法(Scalar Multiplication)"></a>4.3 矩阵乘法(Scalar Multiplication)</h5><p>将值与矩阵每个元素相乘，得到新的矩阵</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-15bc81386707f6b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>矩阵乘法</p>
<h5 id="4-4-矩阵的组合运算-Combination-of-Operands"><a href="#4-4-矩阵的组合运算-Combination-of-Operands" class="headerlink" title="4.4 矩阵的组合运算(Combination of Operands)"></a>4.4 矩阵的组合运算(Combination of Operands)</h5><p>将矩阵加减法和乘除法结合起来，道理都一样</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-833eabb3c17f0db9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>矩阵的组合运算</p>
<h5 id="4-5-两个矩阵相乘"><a href="#4-5-两个矩阵相乘" class="headerlink" title="4.5 两个矩阵相乘"></a>4.5 两个矩阵相乘</h5><p>A矩阵的行 乘 B矩阵的列 得到新矩阵 y 。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-369c408f575cfe44.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>两个矩阵相乘1</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-27438c405289a620.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="img"></p>
<p>两个矩阵相乘2</p>
<h5 id="4-6-矩阵应用到梯度下降算法实例"><a href="#4-6-矩阵应用到梯度下降算法实例" class="headerlink" title="4.6 矩阵应用到梯度下降算法实例"></a>4.6 矩阵应用到梯度下降算法实例</h5><p>把训练集做成一个矩阵，把线性回归方程做成另外一个矩阵，将两个矩阵相乘，最后就能得出一个新的矩阵。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-21341fea26117c6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/695" alt="img"></p>
<p>矩阵应用到梯度下降算法实例图示</p>
<h5 id="4-7-单位矩阵"><a href="#4-7-单位矩阵" class="headerlink" title="4.7 单位矩阵"></a>4.7 单位矩阵</h5><blockquote>
<p>在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,这种矩阵被称为单位矩阵．它是个方阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1。除此以外全都为0。</p>
</blockquote>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-d0a6194ff1a63663.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/698" alt="img"></p>
<p>单位矩阵</p>
<p>除0矩阵外，任何矩阵乘单位矩阵都等于它本身。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-7bf3071433710740.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/569" alt="img"></p>
<p>单位矩阵运算</p>
<h5 id="4-8-逆矩阵"><a href="#4-8-逆矩阵" class="headerlink" title="4.8 逆矩阵"></a>4.8 逆矩阵</h5><p><img src="http://upload-images.jianshu.io/upload_images/3012260-2225b83ba8fbe983.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/551" alt="img"></p>
<p>定义</p>
<p>用octave求得逆矩阵：pinv()函数</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3012260-8b37914823b78864.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/297" alt="img"></p>
<p>octave求得逆矩阵</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">线性回归</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习//" class="article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/02/04/线性回归总结/">more >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/3/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2018 Remaerd
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">GBDT</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">集成学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">KNN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">NLP</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">范数</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">PCA</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">RNN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">SVM</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">决策树</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">朴素贝叶斯</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">概率统计</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">特征工程</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">优化</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">线性回归</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">线性代数</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">逻辑回归</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">一个大数据和机器学习爱好者。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>